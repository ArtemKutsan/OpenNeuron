{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from openneuron.activations import *\n",
    "from openneuron.losses import *\n",
    "from openneuron.optimizers import *\n",
    "from openneuron.initializers import *\n",
    "from openneuron.utils import *\n",
    "\n",
    "decimals = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started with Overall Loss 0.4335 on Train Data\n",
      "Epoch 1/100, Loss: 0.4319, Validation Loss: 0.3012 on Train Data\n",
      "Epoch 10/100, Loss: 0.1408, Validation Loss: 0.1109 on Train Data\n",
      "Epoch 20/100, Loss: 0.0828, Validation Loss: 0.0677 on Train Data\n",
      "Epoch 30/100, Loss: 0.0566, Validation Loss: 0.0481 on Train Data\n",
      "Epoch 40/100, Loss: 0.0422, Validation Loss: 0.0369 on Train Data\n",
      "Epoch 50/100, Loss: 0.0333, Validation Loss: 0.0297 on Train Data\n",
      "Epoch 60/100, Loss: 0.0273, Validation Loss: 0.0247 on Train Data\n",
      "Epoch 70/100, Loss: 0.0230, Validation Loss: 0.0211 on Train Data\n",
      "Epoch 80/100, Loss: 0.0198, Validation Loss: 0.0183 on Train Data\n",
      "Epoch 90/100, Loss: 0.0174, Validation Loss: 0.0162 on Train Data\n",
      "Epoch 100/100, Loss: 0.0154, Validation Loss: 0.0145 on Train Data\n",
      "Training completed with Overall Loss 0.0145 on Train Data\n",
      "\n",
      "Predictions:\n",
      "[[0.0041]\n",
      " [0.1311]\n",
      " [0.1338]\n",
      " [0.8492]]\n",
      "\n",
      "Last forward:\n",
      "Neuron 1, inputs: [1 1], weights: [3.6191 3.5961], bias: -5.487, z: 1.7283, activation: sigmoid, a: 0.8492\n"
     ]
    }
   ],
   "source": [
    "# Класс для нейрона\n",
    "class Neuron:\n",
    "    count = 0\n",
    "\n",
    "    def __init__(self, weights=HeUniform(), bias=HeUniform(), input_size=2, output_size=1, activation=linear, loss=MSE(), optimizer=SGD(momentum=0)):\n",
    "        Neuron.count += 1\n",
    "        self.number = Neuron.count  # номер нейрона\n",
    "        self.id = id(self)\n",
    "        self.layer = None  # ссылка на слой в котором находится нейрон\n",
    "        self.index = None  # индекс нейрона в слое\n",
    "        self.X = None\n",
    "        self.weights = np.array([weights]).T if isinstance(weights, list) else weights(shape=(input_size, output_size))\n",
    "        self.bias = np.array([[bias]]).T if isinstance(bias, (float, int)) else bias(shape=(1, output_size))\n",
    "        self.activation = activation or linear  # функция активации нейрона\n",
    "        self.loss_function = loss or MSE()\n",
    "        self.optimizer = optimizer or SGD(momentum=0)\n",
    "        self.gradient = {'weights': None, 'bias': None}\n",
    "\n",
    "    @property\n",
    "    def Inputs(self):\n",
    "        if self.layer is not None:\n",
    "            return self.layer.Inputs\n",
    "        return self.X\n",
    "    \n",
    "    @Inputs.setter\n",
    "    def Inputs(self, X):\n",
    "        self.X = X\n",
    "\n",
    "    @property\n",
    "    def inputs(self):\n",
    "        return self.Inputs[-1] if self.Inputs is not None else None\n",
    "\n",
    "    @property\n",
    "    def Z(self):\n",
    "        if self.layer is not None:\n",
    "            return self.layer.Z.T[self.index]\n",
    "        return np.dot(self.Inputs, self.weights) + (self.bias.item() if self.bias.item() is not None else 0) if self.Inputs is not None else None\n",
    "\n",
    "    @property\n",
    "    def z(self):\n",
    "        return self.Z[-1].item() if self.Z is not None else None\n",
    "    \n",
    "    @property\n",
    "    def A(self):\n",
    "        if self.layer is not None:\n",
    "            return self.layer.A.T[self.index]\n",
    "        return self.activation(self.Z) if self.Z is not None else None\n",
    "\n",
    "    @property\n",
    "    def a(self):\n",
    "        return self.A[-1].item() if self.A is not None else None\n",
    "    \n",
    "    def activation_derivative(self, Z):\n",
    "        return self.activation(Z, derivative=True)\n",
    "    \n",
    "    def forward(self, Inputs, training=True):\n",
    "        self.Inputs = Inputs\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, error):\n",
    "        self.delta = self.loss_function.loss_derivative(error) * self.activation_derivative(self.Z)\n",
    "        self.gradient['weights'] = np.dot(self.Inputs.T, self.delta)\n",
    "        self.gradient['bias'] = np.sum(self.delta, axis=0)\n",
    "        # return np.dot(self.delta, self.weights.T)  # delta ошибки передаваемая в следующий слой\n",
    "\n",
    "    def update(self):\n",
    "        self.optimizer.update(self)\n",
    "\n",
    "    def fit(self, X, y, epochs=10, batch_size=1, final_batch_size=None, shuffle=True, validation_data=None):\n",
    "        self.X = X\n",
    "        self.epochs = epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.final_batch_size = final_batch_size\n",
    "        \n",
    "        if validation_data is not None:\n",
    "            X_test, y_test = validation_data\n",
    "            val_data_type = 'Test Data'\n",
    "        else:\n",
    "            X_test, y_test = X, y\n",
    "            val_data_type = 'Train Data'\n",
    "        \n",
    "        val_loss = self.loss_function.evaluate_loss(y_test, self.predict(X_test))\n",
    "        print(f'Training started with Overall Loss {val_loss:.4f} on {val_data_type}')\n",
    "        \n",
    "        self.X_len = X.shape[0]\n",
    "        for epoch in range(epochs):\n",
    "            if self.batch_size is not None and self.final_batch_size is not None:\n",
    "                batch_size = self.batch_size + int((self.final_batch_size - self.batch_size) * (epoch + 1) / epochs)\n",
    "            \n",
    "            if shuffle:\n",
    "                permutation = np.random.permutation(self.X_len)\n",
    "                X_shuffled = X[permutation]\n",
    "                y_shuffled = y[permutation]\n",
    "            else:\n",
    "                X_shuffled = X\n",
    "                y_shuffled = y\n",
    "            \n",
    "            epoch_loss = 0\n",
    "            num_batches = 0\n",
    "            \n",
    "            for i in range(0, self.X_len, (batch_size or self.X_len)):\n",
    "                num_batches += 1\n",
    "                X_batch = X_shuffled[i:i+(batch_size or self.X_len)]\n",
    "                y_batch = y_shuffled[i:i+(batch_size or self.X_len)]\n",
    "                \n",
    "                predictions_batch = self.forward(X_batch)\n",
    "                error = self.loss_function.evaluate_error(y_batch, predictions_batch)\n",
    "                loss = self.loss_function.evaluate_loss(y_batch, predictions_batch)\n",
    "                epoch_loss += loss\n",
    "                \n",
    "                self.backward(error)\n",
    "                self.update()\n",
    "            \n",
    "            loss = epoch_loss / num_batches\n",
    "            val_loss = self.loss_function.evaluate_loss(y_test, self.predict(X_test))\n",
    "            \n",
    "            # Выводим на новой строке только каждую 10-ю эпоху\n",
    "            end = '\\n' if (epochs < 10 or epoch == 0 or (epoch + 1) % (epochs // 10) == 0 or epoch == epochs - 1) else '\\r' \n",
    "            print(f'Epoch {epoch + 1}/{epochs}, Loss: {loss:.4f}, Validation Loss: {val_loss:.4f} on {val_data_type}', end=end)\n",
    "        print(f'Training completed with Overall Loss {val_loss:.4f} on {val_data_type}')\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.forward(X, training=False)\n",
    "    \n",
    "    def call(self, X, training=False):\n",
    "        ''' # Метод call вызывается после выполнения встроенного метода __call__.\n",
    "        Служит для дополнения/изменения работы встроенного метода __call__ не нарушая необходимый для правильной работы процесс\n",
    "        вычисления данных при вызове объекта. На вход получает входные данные (массив X). По умолчанию возвращает значение(я) \n",
    "        активированного выхода нейрона (массив A).\n",
    "        '''\n",
    "        # Любой дополнительный код\n",
    "        return self.A\n",
    "\n",
    "    def __call__(self, Inputs, training=False):\n",
    "        self.forward(Inputs, training)\n",
    "        return self.call(Inputs, training)\n",
    "\n",
    "    def __str__(self):\n",
    "        return f'Neuron {format(self.number, decimals=decimals)}, inputs: {format(self.inputs, decimals=decimals)}, ' \\\n",
    "               f'weights: {format(self.weights.flatten(), decimals=decimals)}, bias: {format(self.bias.item(), decimals=decimals)}, ' \\\n",
    "               f'z: {format(self.z, decimals=decimals)}, activation: {self.activation.__name__}, a: {format(self.a, decimals=decimals)}'\n",
    "\n",
    "# Пример AND\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=decimals, suppress=True, threshold=6, edgeitems=2, linewidth=80)\n",
    "\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [1]])\n",
    "\n",
    "X_train, y_train = X, y\n",
    "X_test, y_test = X, y\n",
    "\n",
    "neuron = Neuron(weights=[0.45, -0.12], bias=1.0, activation=sigmoid, loss=MSE(), optimizer=SGD(learning_rate=0.7, momentum=0.3))\n",
    "neuron.fit(X_train, y_train, epochs=100, shuffle=False)\n",
    "\n",
    "# y_pred = neuron.predict(X_test)\n",
    "y_pred = neuron(X_test)\n",
    "print(f'\\nPredictions:\\n{y_pred}')\n",
    "print(f'\\nLast forward:\\n{neuron}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[ 0.3258 -0.2254]\n",
      " [ 0.4611 -0.1781]\n",
      " [ 0.8445 -0.695 ]\n",
      " [ 0.4502  1.1736]], shape=(4, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "initializer = tf.keras.initializers.GlorotNormal()\n",
    "values = initializer(shape=(4, 2))\n",
    "print(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started with Overall Loss 0.2246 on Train Data\n",
      "Epoch 1/25, Loss: 0.2390, Validation Loss: 0.2257 on Train Data\n",
      "Epoch 2/25, Loss: 0.2211, Validation Loss: 0.2077 on Train Data\n",
      "Epoch 4/25, Loss: 0.1795, Validation Loss: 0.1340 on Train Data\n",
      "Epoch 6/25, Loss: 0.1194, Validation Loss: 0.1088 on Train Data\n",
      "Epoch 8/25, Loss: 0.1080, Validation Loss: 0.0925 on Train Data\n",
      "Epoch 10/25, Loss: 0.0859, Validation Loss: 0.0791 on Train Data\n",
      "Epoch 12/25, Loss: 0.0763, Validation Loss: 0.0680 on Train Data\n",
      "Epoch 14/25, Loss: 0.0682, Validation Loss: 0.0607 on Train Data\n",
      "Epoch 16/25, Loss: 0.0578, Validation Loss: 0.0514 on Train Data\n",
      "Epoch 18/25, Loss: 0.0480, Validation Loss: 0.0437 on Train Data\n",
      "Epoch 20/25, Loss: 0.0432, Validation Loss: 0.0380 on Train Data\n",
      "Epoch 22/25, Loss: 0.0399, Validation Loss: 0.0338 on Train Data\n",
      "Epoch 24/25, Loss: 0.0351, Validation Loss: 0.0295 on Train Data\n",
      "Epoch 25/25, Loss: 0.0304, Validation Loss: 0.0276 on Train Data\n",
      "Training completed with Overall Loss 0.0276 on Train Data\n",
      "\n",
      "Predictions:\n",
      "[[0.0122]\n",
      " [0.1696]\n",
      " [0.1669]\n",
      " [0.7685]]\n",
      "\n",
      "Last forward:\n",
      "Neuron 2, inputs: [1 1], weights: [2.7884 2.8077], bias: -4.3962, z: 1.1998, activation: sigmoid, a: 0.7685\n"
     ]
    }
   ],
   "source": [
    "# Пример AND\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=6, edgeitems=2, linewidth=80)\n",
    "\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [1]])\n",
    "\n",
    "X_train, y_train = X, y\n",
    "X_test, y_test = X, y\n",
    "\n",
    "neuron = Neuron(activation=sigmoid, optimizer=Adam(learning_rate=1))\n",
    "neuron.fit(X_train, y_train, epochs=25)\n",
    "\n",
    "# y_pred = neuron.predict(X_test)\n",
    "y_pred = neuron(X_test)\n",
    "print(f'\\nPredictions:\\n{y_pred}')\n",
    "print(f'\\nLast forward:\\n{neuron}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started with Overall Loss 0.7500 on Train Data\n",
      "Epoch 1/5, Loss: 0.5000, Validation Loss: 0.2500 on Train Data\n",
      "Epoch 2/5, Loss: 0.2500, Validation Loss: 0.2500 on Train Data\n",
      "Epoch 3/5, Loss: 0.2500, Validation Loss: 0.0000 on Train Data\n",
      "Epoch 4/5, Loss: 0.0000, Validation Loss: 0.0000 on Train Data\n",
      "Epoch 5/5, Loss: 0.0000, Validation Loss: 0.0000 on Train Data\n",
      "Training completed with Overall Loss 0.0000 on Train Data\n",
      "\n",
      "Predictions:\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "\n",
      "Last forward:\n",
      "Neuron 3, inputs: [1 1], weights: [1.7723 0.9568], bias: -0.2989, z: 2.4302, activation: heaviside, a: 1\n"
     ]
    }
   ],
   "source": [
    "# Пример OR\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=6, edgeitems=2, linewidth=80)\n",
    "\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([[0],\n",
    "              [1],\n",
    "              [1],\n",
    "              [1]])\n",
    "\n",
    "X_train, y_train = X, y\n",
    "X_test, y_test = X, y\n",
    "\n",
    "neuron = Neuron(activation=heaviside, loss=MAE(), optimizer=SGD(learning_rate=1, momentum=0))\n",
    "neuron.fit(X_train, y_train, epochs=5)\n",
    "\n",
    "# y_pred = neuron.predict(X_test)\n",
    "y_pred = neuron(X_test)\n",
    "print(f'\\nPredictions:\\n{y_pred}')\n",
    "print(f'\\nLast forward:\\n{neuron}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started with Overall Loss 0.2500 on Train Data\n",
      "Epoch 1/10, Loss: 0.5000, Validation Loss: 0.2500 on Train Data\n",
      "Epoch 2/10, Loss: 0.7500, Validation Loss: 0.2500 on Train Data\n",
      "Epoch 3/10, Loss: 0.2500, Validation Loss: 0.5000 on Train Data\n",
      "Epoch 4/10, Loss: 0.5000, Validation Loss: 0.5000 on Train Data\n",
      "Epoch 5/10, Loss: 0.2500, Validation Loss: 0.0000 on Train Data\n",
      "Epoch 6/10, Loss: 0.0000, Validation Loss: 0.0000 on Train Data\n",
      "Epoch 7/10, Loss: 0.0000, Validation Loss: 0.0000 on Train Data\n",
      "Epoch 8/10, Loss: 0.0000, Validation Loss: 0.0000 on Train Data\n",
      "Epoch 9/10, Loss: 0.0000, Validation Loss: 0.0000 on Train Data\n",
      "Epoch 10/10, Loss: 0.0000, Validation Loss: 0.0000 on Train Data\n",
      "Training completed with Overall Loss 0.0000 on Train Data\n",
      "\n",
      "Predictions:\n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "\n",
      "Last forward:\n",
      "Neuron 4, inputs: [1 1], weights: [1.2071 0.9364], bias: -1.3036, z: 0.8399, activation: heaviside, a: 1\n"
     ]
    }
   ],
   "source": [
    "# Пример AND\n",
    "# Настройка вывода для удобочитаемости\n",
    "np.set_printoptions(precision=4, suppress=True, threshold=6, edgeitems=2, linewidth=80)\n",
    "\n",
    "X = np.array([[0, 0], \n",
    "              [0, 1],\n",
    "              [1, 0],\n",
    "              [1, 1]])\n",
    "y = np.array([[0],\n",
    "              [0],\n",
    "              [0],\n",
    "              [1]])\n",
    "\n",
    "X_train, y_train = X, y\n",
    "X_test, y_test = X, y\n",
    "\n",
    "neuron = Neuron(activation=heaviside, loss=MAE(), optimizer=SGD(learning_rate=1, momentum=0))\n",
    "neuron.fit(X_train, y_train, epochs=10)\n",
    "\n",
    "# y_pred = neuron.predict(X_test)\n",
    "y_pred = neuron(X_test)\n",
    "print(f'\\nPredictions:\\n{y_pred}')\n",
    "print(f'\\nLast forward:\\n{neuron}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
