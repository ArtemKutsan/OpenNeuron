{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С чего все началось\n",
    "\n",
    "Для ознакомления с тем, что такое перцептрон, можно почитать статью на Википедии. Там представлена краткая история, довольно подробное объяснение, и в целом всё, что нам потребуется, и даже больше. В статье, помимо прочего, в разделе \"Историческая классификация\" говорится следующее:\n",
    "\n",
    "*\"Понятие перцептрона имеет интересную, но незавидную историю. В результате неразвитой терминологии нейронных сетей прошлых лет, резкой критики и непонимания задач исследования перцептронов, а иногда и ложного освещения прессой, изначальный смысл этого понятия исказился.\"*\n",
    "\n",
    "И далее:\n",
    "\n",
    "*Сравнивая разработки Розенблатта и современные обзоры и статьи, можно выделить 4 довольно обособленных класса перцептронов:*\n",
    "\n",
    "1. **Перцептрон с одним скрытым слоем**: классический перцептрон, описанный в книгах Розенблатта. Содержит по одному слою S-, A- и R-элементов.\n",
    "2. **Однослойный перцептрон**: простейшая сеть прямого распространения с входами, напрямую соединёнными с выходами. Это линейный классификатор, который не может решать задачи с нелинейными зависимостями, такие как XOR.\n",
    "3. **Многослойный перцептрон (по Розенблатту)**: перцептрон с дополнительными слоями A-элементов. Анализировался Розенблаттом в его книге.\n",
    "4. **Многослойный перцептрон (по Румельхарту)**: включает дополнительные слои A-элементов и обучается методом обратного распространения ошибки. Является расширением перцептрона Розенблатта.\n",
    "\n",
    "Также полезно будет ознакомиться с разделами \"Алгоритмы обучения\" и \"Традиционные заблуждения\". Пересказывать всю статью не вижу смысла. Разбирать подробно различные реализации и писать для них код также не имеет смысла, так как с тех пор многое изменилось, хотя путаница в терминологии тех лет, на мой взгляд, всё ещё остаётся. Лично для себя я выделил несколько понятий, которые на мой взгляд являются ключевыми. Эти понятия я и собираюсь разобрать, и на их основе писать свою реализацию нейронной сети.\n",
    "\n",
    "Итак, по порядку:\n",
    "\n",
    "1. **Перцептрон/нейрон (однослойный перцептрон)**: простейшая сеть прямого распространения с входами, напрямую соединёнными с выходами. Это линейный классификатор, который не может решать задачи с нелинейными зависимостями, такие как XOR. Для простоты такой объект я буду называть перцептроном или нейроном.\n",
    "2. **Нейронная сеть (многослойный перцептрон)**: включает дополнительные слои и обучается методом обратного распространения ошибки. Является расширением перцептрона Розенблатта. Для простоты это я буду называть нейронной сетью.\n",
    "3. **Общий алгоритм обучения**: обучение с учителем, метод обратного распространения ошибки.\n",
    "\n",
    "Эти три пункта я взял за основу, и вокруг них будет написан весь код. Как видите, по сравнению со статьей на Википедии, я значительно всё упростил, но, забегая вперед, скажу, что в финальной реализации нам даже такое, казалось бы, основное понятие как нейрон не особенно будет нужно, потому что все вычисления будут происходить на уровне слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Еще не Перцептрон\n",
    "\n",
    "**Краткое вступление о том, что такое перцептрон.**\n",
    "\n",
    "Перцептрон был изобретён в 1957 году Фрэнком Розенблаттом, американским психологом и специалистом по нейронным сетям. Он разработал перцептрон как алгоритм машинного обучения, который может классифицировать входные данные на основе их линейных свойств. Перцептрон представлял собой одну из первых моделей искусственного нейрона, способную к обучению и распознаванию образов. Таким образом, перцептрон можно кратко описать как алгоритм для классификации данных. Давайте попробуем создать такой алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Общий алгоритм (обучение с учителем)\n",
    "\n",
    "Начну не с самого перцептрона, а с общего алгоритма задачи. Предположим, что у нас есть какие-то данные, которые мы назовём входными данными (сигналами). Также мы знаем, каким должен быть результат — назовём его выходными данными. Наша задача — написать программу, которая будет получать на входе эти данные, затем производить над ними определённые вычисления (сложение или умножение входных данных на некоторые заданные значения) и выдавать ответ. Если этот ответ не соответствует ожидаемому, программа должна изменить некоторые из своих параметров, чтобы ответы совпадали.\n",
    "\n",
    "Кажется запутанным? На самом деле, всё гораздо проще, чем может показаться на первый взгляд. По сути, нам нужно найти решение уравнения путём \"подбора\"/изменения некоторых его переменных. Эти переменные можно назвать коэффициентами, или, как их общепринято называть, весами и смещением.\n",
    "\n",
    "Тут можно сделать небольшое отступление в сторону школьной математики и увидеть, что далее в коде мы решаем уравнение вида \n",
    "`f(x) = a*x + b`, где `f(x)` — это функция от `x `и наше значение `y`, `a` — это наш вес (`weight`), а `b` — это наше смещение (`bias`). Для такого уравнения существует простое математическое решение по нахождению корней. Зачем тогда я изобретаю велосипед и решаю его с помощью нейронных сетей? Однако это лишь самый упрощённый пример, который помогает понять основные идеи, лежащие в основе обучения нейронных сетей. В реальности нейронные сети используются для решения гораздо более сложных, нелинейных задач, где простой линейной зависимости недостаточно, и требуются более сложные алгоритмы, такие, например, как обучение методом обратного распространения ошибки."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные (x): 1\n",
      "Ожидаемое/необходимое значение (y): 1\n",
      "Начальные значения (до обучения) веса (weight): -0.5 и смещения (bias): 0.25\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных 1 предсказанное значение: 0 (output: -0.25), ожидаемое/истинное значение: 1\n",
      "\n",
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weight: -0.40, bias: 0.35\n",
      "Эпоха обучения 2/5, weight: -0.30, bias: 0.45\n",
      "Эпоха обучения 3/5, weight: -0.20, bias: 0.55\n",
      "Эпоха обучения 4/5, weight: -0.10, bias: 0.65\n",
      "Эпоха обучения 5/5, weight: -0.10, bias: 0.65\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных 1 предсказанное значение: 1 (output: 0.55), ожидаемое/истинное значение: 1\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм (обучение с учителем)\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "x = 1\n",
    "y = 1\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения веса и смещения в процессе обучения\n",
    "h = 0.1  # размер шага изменения веса и смещения\n",
    "\n",
    "# Вес и смещение\n",
    "weight = -0.5  # начальный вес (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 0.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Выход нашей программы до обучения \n",
    "output = x * weight + bias  # мы взяли наши входные данные (x), умножили на вес (weight) и прибавили смещение (bias)\n",
    "# Функция активации: ступенчатая/пороговая функция (порог 0.5)\n",
    "if output >= 0.5:\n",
    "    prediction = 1  # все, что выше и равно 0.5, считается 1\n",
    "else:\n",
    "    prediction = 0  # все, что ниже 0.5, считается 0\n",
    "print(f'Входные данные (x): {x}')\n",
    "print(f'Ожидаемое/необходимое значение (y): {y}')\n",
    "print(f'Начальные значения (до обучения) веса (weight): {weight} и смещения (bias): {bias}')\n",
    "\n",
    "print('\\nТест до обучения')\n",
    "print(f'Для входных данных {x} предсказанное значение: {prediction} (output: {output:.2f}), ожидаемое/истинное значение: {y}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Вычисление взвешенной (weight) суммы входного сигнала (x) и смещения (bias)\n",
    "    output = x * weight + bias  # это то, что выдает/предсказывает наш алгоритм\n",
    "    \n",
    "    # Функция активации: ступенчатая/пороговая функция (порог 0.5)\n",
    "    if output >= 0.5:\n",
    "        prediction = 1  # все, что выше и равно 0.5, считается 1\n",
    "    else:\n",
    "        prediction = 0  # все, что ниже 0.5, считается 0\n",
    "    \n",
    "    # Вычисление ошибки\n",
    "    error = y - prediction\n",
    "    \n",
    "    # Обновление/изменение веса и смещения на основе ошибки error и с использованием шага h\n",
    "    weight += h * error * x\n",
    "    bias += h * error\n",
    "    \n",
    "    # Отладочная информация\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weight: {weight:.2f}, bias: {bias:.2f}')\n",
    "\n",
    "# Предсказание (выход) на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "output = x * weight + bias\n",
    "if output >= 0.5:\n",
    "    prediction = 1\n",
    "else:\n",
    "    prediction = 0\n",
    "print(f'Для входных данных {x} предсказанное значение: {prediction} (output: {output:.2f}), ожидаемое/истинное значение: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выше демонстрирует общий алгоритм обучения нейрона/перцептрона. Алгоритм обучения нейронной сети несколько сложнее, но в целом похож. Конечно, в коде пока нет никакой сети и даже нет никаких нейронов, а также отсутствует одна из важнейших концепций нейронных сетей, такая как МОР (метод обратного распространения ошибки). Однако, в нем есть такие понятия как вычисление ошибки и корректировка параметров на основе этой ошибки. В целом, код демонстрирует общий алгоритм того, что происходит при обучении.\n",
    "\n",
    "Код написан специально максимально упрощенно, без использования массивов, матриц, сторонних библиотек, функций, ООП и других сложных концепций. Все это будет добавляться постепенно. В конце у нас будет полноценная реализация нейронной сети со слоями и нейронами на основе объектов и классов, с множеством различных функций и даже небольшим ~~костылем~~ классом для Keras, с помощью которого мы сможем сравнить результаты работы нашей простой нейронной сети с результатами, которые выдает аналогичная нейронная сеть, построенная на Keras."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Разбор общего алгоритма обучения\n",
    "\n",
    "Итак, давайте разберём и сразу же улучшим наш код. На самом деле, задача, которую мы решаем выше, довольно бесполезная и не имеет практического смысла. Повторюсь, она лишь демонстрирует алгоритм обучения нейрона/перцептрона. То есть она показывает, что алгоритм получает входные данные, производит с ними определённые операции (сложение/умножение), сравнивает результат с тем, который мы задали как правильный, и если ответ не совпадает, алгоритм корректирует вес и смещение так, чтобы ответ совпадал с верным.\n",
    "\n",
    "Изначально мы задали вес и смещение как: `weight = -0.5`, `bias = 0.25`. Наши входные данные были просто одним числом: `x = 1`, и мы сказали, что `y` (правильный ответ) должен быть равен 1. Наша функция вычисления `y` выглядит так: `output = x * weight + bias`. `Output` — это то, что мы получаем, и мы ожидаем, что он будет равен 1. Получается: `output = 1 * (-0.5) + 0.25 = -0.25`. Применяем к значению `-0.25` функцию активации. Порог `0.5` в функции активации выбран потому, что я хочу разделить получаемые сетью ответы на два класса: 0 — это объекты одного класса, 1 — это объекты другого класса. В данном случае, если `output >= 0.5`, мы говорим, что предсказали для `x = 1` ответ 0. Это неправильно, так как мы ожидаем ответ 1. Мы считаем ошибку: `error = y - prediction`, или `error = 1 - 0 = 1`. То есть ошибка равна 1. Далее мы корректируем вес и смещение, используя эту ошибку: `weight += h * error * x`, `weight += 0.1 * 1 * 1`, `weight += 0.1`, то есть `weight = -0.5 + 0.1`, `weight = -0.40`. Таким же образом изменяем смещение: `bias += 0.1 * 1`, `bias += 0.1`, то есть `bias = 0.25 + 0.1`, `bias = 0.35`.\n",
    "\n",
    "Первая эпоха завершена. Теперь у нас `weight = -0.40`, а `bias = 0.35`. Какой же теперь `output`? `Output = 1 * (-0.40) + 0.35 = -0.05`. Напомню, что при начальных значениях веса и смещения `output` был `-0.25`. Мы видим, что результат стал ближе к 1, но наш прогноз после применения функции активации всё равно 0, так как функция активации даст прогноз 1, если наш `output` будет равен или больше 0.5. Но мы указали 5 эпох для обучения, поэтому начинаем вторую. Можете сами подставить вес и смещение в формулу `output = x * weight + bias`, посчитать результат и ошибку, и убедиться в том, что наш вес и смещение станут: `weight = -0.30`, `bias = 0.45`. Теперь `output = 1 * (-0.30) + 0.45 = 0.15`, то есть ещё ближе к нашему правильному ответу. Проделав 4 эпохи обучения, наши вес и смещение станут: `weight = -0.10`, `bias = 0.65`. И `output` станет: `output = 1 * (-0.10) + 0.65 = 0.55`. Теперь наше предсказание после активации для `x = 1` станет 1 (`0.55 > 0.5`). Значит, наша ошибка теперь будет: `error = 1 - 1 = 0`. То есть вес и смещение не изменятся: `weight += 0 * 0.1 * 1`, `weight += 0`, `weight = -0.10`, как и было. То же самое произойдёт для смещения. Как видим, на 5-й эпохе обучения вес и смещение не изменились. В качестве примера можно изменить целевое значение `y` и начальное значение `bias`, и посмотреть, как будут изменяться вес и смещение. Также мы немного улучшим наш код, оформив функцию активации как отдельную функцию в программе."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные (x): 1\n",
      "Ожидаемое/необходимое значение (y): 0\n",
      "Начальные значения (до обучения) веса (weight): -0.5 и смещения (bias): 1.25\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных 1 предсказанное значение: 1 (output: 0.75), ожидаемое/истинное значение: 0\n",
      "\n",
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weight: -0.60, bias: 1.15\n",
      "Эпоха обучения 2/5, weight: -0.70, bias: 1.05\n",
      "Эпоха обучения 3/5, weight: -0.70, bias: 1.05\n",
      "Эпоха обучения 4/5, weight: -0.70, bias: 1.05\n",
      "Эпоха обучения 5/5, weight: -0.70, bias: 1.05\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных 1 предсказанное значение: 0 (output: 0.35), ожидаемое/истинное значение: 0\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "x = 1\n",
    "y = 0\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения веса и смещения в процессе обучения\n",
    "h = 0.1  # размер шага изменения веса и смещения\n",
    "\n",
    "# Вес и смещение\n",
    "weight = -0.5  # начальный вес (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 1.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Функция активации: ступенчатая/пороговая функция (порог 0.5)\n",
    "def activation(value):\n",
    "    return 1 if value >= 0.5 else 0\n",
    "\n",
    "# Выход нашей программы до обучения \n",
    "output = x * weight + bias  # мы взяли наши входные данные (x), умножили на вес (weight) и прибавили смещение (bias)\n",
    "predicton = activation(output)\n",
    "print(f'Входные данные (x): {x}')\n",
    "print(f'Ожидаемое/необходимое значение (y): {y}')\n",
    "print(f'Начальные значения (до обучения) веса (weight): {weight} и смещения (bias): {bias}')\n",
    "\n",
    "print('\\nТест до обучения')\n",
    "print(f'Для входных данных {x} предсказанное значение: {prediction} (output: {output:.2f}), ожидаемое/истинное значение: {y}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Вычисление взвешенной (weight) суммы входного сигнала (x) и смещения (bias)\n",
    "    output = x * weight + bias  # это то, что выдает/предсказывает наш алгоритм\n",
    "    prediction = activation(output)\n",
    "    \n",
    "    # Вычисление ошибки\n",
    "    error = y - prediction\n",
    "    \n",
    "    # Обновление/изменение веса и смещения на основе ошибки error и с использованием шага h\n",
    "    weight += h * error * x\n",
    "    bias += h * error\n",
    "    \n",
    "    # Отладочная информация\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weight: {weight:.2f}, bias: {bias:.2f}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "output = x * weight + bias\n",
    "predicton = activation(output)\n",
    "print(f'Для входных данных {x} предсказанное значение: {prediction} (output: {output:.2f}), ожидаемое/истинное значение: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы видим, что изначально у нас было предсказание 1 а мы ожидали 0. Используя ошибку предсказания мы немного подкоррестировали вес и смещение и получили уже на второй эпохе нужный результат."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Общие понятия и терминология\n",
    "\n",
    "Давайте определимся с некоторыми понятиями и необходимой терминологией для дальнейшего продвижения и обобщим алгоритм обучения.\n",
    "\n",
    "1. **Входные данные (`X`)**:\n",
    "   - Набор данных, подаваемый на вход модели (сети/слоя/нейрона) для обучения или предсказания. Обычно представляется в виде матрицы, где строки соответствуют примерам, а столбцы — признакам. Мы пока будем пользоваться списками в котороых каждый элемент это значение некоторго параметра объекта или фича от английского features. В наборе X содержатся объекты x со своими признаками. \n",
    "   \n",
    "2. **Целевая метка (`y`)**:\n",
    "   - Значения, которые модель должна предсказать. В задаче классификации это могут быть классы, а в задаче регрессии — числовые значения.\n",
    "   \n",
    "3. **Вес(а) (`weights`)**:\n",
    "   - Параметры модели, которые обучаются в процессе тренировки. Влияние каждого признака на итоговое предсказание регулируется весами.\n",
    "   \n",
    "4. **Смещение (`bias`)**:\n",
    "   - Дополнительный параметр модели, который помогает лучше подгонять модель под данные. Он позволяет модели предсказывать ненулевые значения, даже если все входные признаки равны нулю.\n",
    "   \n",
    "5. **Значение `z` (значение функции или вычисленное значение взвешенной суммы входных данных и смещения)**:\n",
    "   - Промежуточное значение, вычисляемое как линейная комбинация входных данных и весов, с добавлением смещения.\n",
    "   - Формула: `z = weights * x + bias`. Если, например, входныеданные это один объект `x = [1, 0]` из выборки `X`, то у нейрона на вход которому будут поступать эти данные также должно быть два веса, например `weights = [0.25, -0.5]` и если у нейрона есть `bias = 0.75` например, то наше значение  функции будет вычисляться так: `z = w1*x1 + w2*x2 + bias`, то есть `z` на каждом этапе будет вычисляться по такой формуле (конечно это если у нас просто один нейрон, в случае сети формула `z` и кол-во весов следующего слоя будет зависеть от кол-ва нейронов в предыдущем слое).   \n",
    "\n",
    "6. **Функция активации (activation function или просто `activation`)**:\n",
    "   - Функция, применяемая к промежуточному значению `z`, чтобы ввести нелинейность в модель и помочь ей решать сложные задачи.\n",
    "   - Пример: `ReLU (Rectified Linear Unit)`, `sigmoid`, `tanh`. У перцептрона который мы создадим ступенчатая функция активации которая называется часто `heaviside`.\n",
    "\n",
    "7. **Выход (`output` или просто `a` в смысле значения активации)**:\n",
    "   - Конечное предсказание модели, которое получается после применения функции активации к промежуточному значению `z`. Тут кстати внимательный читатель заметит, что я ранее называл `output`-ом значение `z`. Я так делал для упрощения понимания работы алгоритмя на начатьных этапах. Далее я буду использовать `z` и `a` вместо `output`. \n",
    "\n",
    "8. **Ошибка (`loss`/`error`)**:\n",
    "   - Разница между предсказанным значением и реальной целевой меткой. Ошибка используется для оценки качества модели и дальнейшего её обучения. В задачах регрессии может использоваться MSE (Mean Squared Error), а в задачах классификации — Categorical Cross-Entropy. Тут так же можно заметить, что мы вычисляем ошибку как `y - prediction`, а в первом предложении говорится, что это разница `prediction - y`. На самом деле это не принципиально. Просто мы пользуемся `y - prediction` так как это интуитивно более понятно. Но мы можем так же пользоватьмся и `prediction - y` просто тогда мы должны менять веса не `weights +=` а `weights -=`. Пока мы будем пользоваться только понятием `error` для упрощения и считать ошибку как `y - prediction`. Возможно далее, в процессе реализации Categorical Cross-Entropy станет понятно почему там используется `prediction - y`.\n",
    "\n",
    "9. **Функция потерь (loss function)**:\n",
    "   - Функция, которая вычисляет ошибку. Она служит для того, чтобы алгоритм мог понять, насколько хорошо или плохо он работает и как ему нужно скорректировать свои параметры, например MSE или Cross-Entropy. Опять же пока не будем использовать это чтобы не усложнять.  \n",
    "\n",
    "10. **Предсказание (`prediction`)**:\n",
    "    - Значение, которое модель возвращает после обработки входных данных. В идеале оно должно быть близким к истинному значению. В задаче классификации, например, это может быть класс, к которому, по мнению модели, относится входной пример."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Обобщенное описание процесса обучения и предсказания\n",
    "\n",
    "1. **Подготовка данных**: Определяем входные данные `X` или просто один пример `x` и целевые метки `y`.\n",
    "\n",
    "2. **Инициализация модели**: Устанавливаем начальные значения весов и смещений.\n",
    "\n",
    "3. **Метод/процесс прямого распространения (Forward Pass)**:\n",
    "   - \"Подаем\" наши данные в сеть/нейрон. \n",
    "   - Вычисляем промежуточное значение `z` для всех нейпонов/слов сети или просто для одного нейрона.\n",
    "   - Применяем функцию активации к `z`, получая `a` (`output`).\n",
    "\n",
    "4. **Вычисление ошибки**:\n",
    "   - Сравниваем значение активированного выхода `a` (`output`) с истинным значением `y`.\n",
    "   - Используем функцию потерь для расчета ошибки. Пока просто будем использовать значение `error`.\n",
    "\n",
    "5. **Метод/процесс обратного распространения (Backward Pass)**:\n",
    "   - Вычисляем градиенты функции потерь по отношению к весам и смещениям на выходном слое/нейроне. Вот тут мы пока не будем пользоваться понятием градиент и производная. Да и в целом пока мы не перейдем непосредственно к сети из слоев с нейронами мы не будем называть это методом обратного распространения ошибки (МОР), так как она (ошибка) пока еще не распространияется у нас, то есть не передается в предыдущие слои сети.\n",
    "   - Обновляем веса и смещения с использованием алгоритма оптимизации, например, градиентного спуска. Тут туже пока несколько упростим процесс и не будем применять понятие \"алгоритм оптимизации\" опять же для упрощения на начальных этапах.\n",
    "\n",
    "6. **Повторение**:\n",
    "   - Повторяем шаги 3-5 на протяжении заданного количества эпох или до достижения приемлемого уровня ошибки.\n",
    "\n",
    "7. **Предсказание**:\n",
    "   - После обучения модели, подаем новые данные на вход и получаем предсказание. Так как для начала мы не будем использовать большие выборки которые должны быть разделены на обучающую и тестовую, то проедсказывать мы будем то на чем обучались. Это неправильно но опять же зависит от задачи.\n",
    "\n",
    "В итоге хочется сказать, что некоторые неточности в терминологии допущены вынужденно/намерено для общего упрощения понимания задачи. В дальнейшем все эти неточности будут естесственным образом исправлены.\n",
    "\n",
    "Итак давайте перейдем от задачи которая в принципе имела мало смысла к чему-то более осмысленному. А именно давайте теперь рассмотрим некий один объект `x` нашей некой выборки `X`, у которого есть два признака. Те есть `x = [1, 0]`. Перепишем наш код с учетом той терминологии что мы описали выше, также обобщим формулу вычисления `z`, и добавим еще функций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные (x): [1, 0]\n",
      "Ожидаемое/необходимое значение (y): 0\n",
      "Начальные значения (до обучения) весов (weights): [-0.5, -1.25] и смещения (bias): 1.75\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 1, ожидаемое/истинное значение: 0\n",
      "\n",
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weights: [-0.6, -1.25], bias: 1.65\n",
      "Эпоха обучения 2/5, weights: [-0.7, -1.25], bias: 1.55\n",
      "Эпоха обучения 3/5, weights: [-0.8, -1.25], bias: 1.45\n",
      "Эпоха обучения 4/5, weights: [-0.9, -1.25], bias: 1.35\n",
      "Эпоха обучения 5/5, weights: [-0.9, -1.25], bias: 1.35\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 0, ожидаемое/истинное значение: 0\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "x = [1, 0]  # объект с двумя признаками\n",
    "y = 0\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения весов и смещения в процессе обучения\n",
    "h = 0.1  # размер шага изменения весов и смещения\n",
    "\n",
    "# Веса и смещение\n",
    "weights = [-0.5, -1.25]  # начальные веса (эти параметры мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 1.75  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Функция активации: ступенчатая/пороговая функция (порог 0.5)\n",
    "def activation(z):\n",
    "    return 1 if z >= 0.5 else 0\n",
    "\n",
    "# Функция предсказания\n",
    "def predict(x):\n",
    "    # z = x1*w1 + x2*w2 + ... + xn*wn + bias\n",
    "    z = sum(xi * wi for xi, wi in zip(x, weights)) + bias  # взвешенная сумма\n",
    "    a = activation(z)  # активация\n",
    "    return a  # возвращаем значение активации (prediction)\n",
    "\n",
    "# Функция обновления/изменения весов и смещения на основе ошибки\n",
    "def update(weights, bias, error, x):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] += h * error * x[i]\n",
    "    bias += h * error\n",
    "    return weights, bias\n",
    "\n",
    "# Выход/прогноз нашей программы до обучения \n",
    "prediction = predict(x)\n",
    "print(f'Входные данные (x): {x}')\n",
    "print(f'Ожидаемое/необходимое значение (y): {y}')\n",
    "print(f'Начальные значения (до обучения) весов (weights): {weights} и смещения (bias): {bias:.2f}')\n",
    "\n",
    "print('\\nТест до обучения')\n",
    "print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Получение предсказания\n",
    "    prediction = predict(x)\n",
    "    \n",
    "    # Вычисление ошибки\n",
    "    error = y - prediction\n",
    "    \n",
    "    # Обновление/изменение весов и смещения на основе ошибки\n",
    "    weights, bias = update(weights, bias, error, x)\n",
    "    \n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "prediction = predict(x)\n",
    "print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом нет смысла разбирать всё повторно, так как разбор аналогичен предыдущему. Главное — понять, что объекты `x`, подаваемые в сеть, будут иметь свои признаки, и сеть должна обучить веса таким образом, чтобы правильно классифицировать эти объекты (в случае задачи классификации). На что можно обратить внимание, так это на то, что, как видно из результатов, наш второй вес не обучается. Это происходит потому, что наш единственный объект `x` имеет два признака, и один из них равен 0. Поэтому при расчёте изменения второго веса происходит умножение на 0, и, следовательно, второй вес изменяется на 0, то есть остаётся неизменным. \n",
    "\n",
    "Следующий шаг — это переход к ООП и представление всей модели сети как совокупности взаимодействующих объектов (нейронов, слоёв, оптимизаторов и других). Но перед тем как перейти к ООП, и все это реализовывать, сделаем ещё один небольшой шаг: добавим в наш набор ещё один признак и посмотрим на процесс обучения, чтобы окончательно закрепить понимание того, что происходит при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Почти Логическое И (AND)\n",
    "\n",
    "Что такое \"Логическое И (AND)\" и как наш Перцептрон (нейрон с пороговой функцией активации) решает эту задачу, мы подробно рассмотрим далее. Перед окончательным переходом к ООП давайте кратко рассмотрим ещё один пример. Прежде чем писать класс для Перцептрона, проанализируем выборку из двух объектов и посмотрим на процесс обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Входные данные (X): [[1, 0], [1, 1]]\n",
      "Ожидаемые/необходимые значения (y): [0, 1]\n",
      "Начальные значения (до обучения) весов (weights): [-0.5, -1.25] и смещения (bias): 1.75\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 1, ожидаемое/истинное значение: 0\n",
      "Для входных данных [1, 1] предсказанное значение: 0, ожидаемое/истинное значение: 1\n",
      "\n",
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weights: [-0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/5, weights: [-0.5, 0.75], bias: 1.75\n",
      "Эпоха обучения 3/5, weights: [-0.5, 1.75], bias: 1.75\n",
      "Эпоха обучения 4/5, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 5/5, weights: [-1.5, 1.75], bias: 0.75\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 0, ожидаемое/истинное значение: 0\n",
      "Для входных данных [1, 1] предсказанное значение: 1, ожидаемое/истинное значение: 1\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения весов и смещения в процессе обучения\n",
    "h = 1  # размер шага изменения весов и смещения\n",
    "\n",
    "# Веса и смещение\n",
    "weights = [-0.5, -1.25]  # начальные веса (эти параметры мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 1.75  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Функция активации: ступенчатая/пороговая функция (порог 0.5)\n",
    "def activation(z):\n",
    "    return 1 if z >= 0.5 else 0\n",
    "\n",
    "# Функция предсказания\n",
    "def predict(x):\n",
    "    # z = x1*w1 + x2*w2 + ... + xn*wn + bias\n",
    "    z = sum(xi * wi for xi, wi in zip(x, weights)) + bias  # взвешенная сумма\n",
    "    a = activation(z)  # активация\n",
    "    return a  # возвращаем значение активации (prediction)\n",
    "\n",
    "# Функция обновления/изменения весов и смещения на основе ошибки\n",
    "def update(weights, bias, error, x):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] += h * error * x[i]\n",
    "    bias += h * error\n",
    "    return weights, bias\n",
    "\n",
    "print(f'Входные данные (X): {X}')\n",
    "print(f'Ожидаемые/необходимые значения (y): {y}')\n",
    "print(f'Начальные значения (до обучения) весов (weights): {weights} и смещения (bias): {bias:.2f}')\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "for x, y_true in zip(X, y):\n",
    "    prediction = predict(x)\n",
    "    print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y_true}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    for x, y_true in zip(X, y):    \n",
    "        # Получение предсказания\n",
    "        prediction = predict(x)\n",
    "        \n",
    "        # Вычисление ошибки\n",
    "        error = y_true - prediction\n",
    "        \n",
    "        # Обновление/изменение веса и смещения на основе ошибки\n",
    "        weights, bias = update(weights, bias, error, x)\n",
    "    \n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "for x, y_true in zip(X, y):\n",
    "    prediction = predict(x)\n",
    "    print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y_true}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличии от предыдущего примера, можно заметить, что в процессе обучения обучаются уже оба веса и смещение. Таким образом наша программа с изначальными весами неправильно классифицировала оба объекта, но после 5 эпох обучения веса были подстроены так, что оба объекта стали классифицироваться правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Почти Перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему почти станет понятно чуть дальше. Пока давайте разберем код для класса Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        \"\"\"\n",
    "        Инициализирует перцептрон с заданными весами и смещением.\n",
    "        \n",
    "        :param weights: Список начальных весов.\n",
    "        :param bias: Начальное значение смещения. По умолчанию None.\n",
    "        \"\"\"\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        \"\"\"\n",
    "        Пороговая функция активации (функция Хевисайда).\n",
    "        \n",
    "        :param z: Взвешенная сумма входов и смещения.\n",
    "        :return: 1, если z >= 0.5, иначе 0.\n",
    "        \"\"\"\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Подает/\"прогоняет\" данные в/через перцептрон, вычисляет взвешенную сумму и применяет функцию активации.\n",
    "        \n",
    "        :param inputs: Список входных значений (набор признаков объекта).\n",
    "        :return: Результат применения функции активации.\n",
    "        \"\"\"\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = inputs\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Подает/\"прогоняет\" весь набор данных в/через перцептрон.\n",
    "        \n",
    "        :param X: Список списков или массив входных значений (набор признаков объекта).\n",
    "        :return: Список результатов активации для каждого набора входных значений (для каждого объекта из выборки).\n",
    "        \"\"\"\n",
    "        return [self.forward(x) for x in X]\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Возвращает строковое представление объекта перцептрон.\n",
    "        \n",
    "        :return: Строка с текущими значениями атрибутов перцептрона (значениями атрибутов рассчитанные при последнем \"прогоне\").\n",
    "        \"\"\"\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед нами класс с названием `Perceptron`. Для чего он нужен? Он нужен для создания разных объектов этого класса. Что такое объект? Тут приходит на ум только бессмысленное объяснение, вроде того, что объект это объект. Так как это не курс по ООП, я попытаюсь объяснить только общие моменты или только то, что мы непосредственно используем.\n",
    "\n",
    "Итак, объект — это некая сущность ~~в виде гномика~~, которая обладает какими-то свойствами/атрибутами, если мы говорим о классе объекта и какими-то методами (для понимания это некие функции). Этот самый объект может принимать какие-то данные, как та же функция, например, и производить с этими данными какие-то вычисления, менять как-то свое состояние (значение своих параметров), взаимодействовать с другими объектами или функциями при этом в одной программе может быть много объектов разных классов и они могут каким-то образом друг с другом взаимодействовать описывая какие-то сложные процессы и понятия. Например дольше мы будем объеденять несколько объектов класса перцептрон в объекте класса слой, а объекты класса слой будут определенным образом взаимодействовать между собой, а все это вместе будет объектом класса нейронная сеть со своими методами и свойствами.\n",
    "\n",
    "Наверное, звучит довольно запутанно, но на самом деле, когда разобрался в концепции ООП, то потом все подряд начинаешь писать в этом стиле. Зачем это нужно? Дело в том, что при написании достаточно сложных программ и при решении сложных задач довольно быстро сталкиваешься с тем, что код разрастается, и поддерживать и прослеживать логику становится все сложнее. В коде могут быть сотни и тысячи разных функций и еще больше переменных и параметров. Это все бесконечно усложняет.\n",
    "\n",
    "Поэтому переход к объектно-ориентированной концепции программирования в значительной мере упрощает понимание кода и позволяет описывать более сложные сущности и оперировать более сложными абстракциями, что в свою очередь помогает создавать более сложные в плане продвинутости программы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей первоначальной программе были некоторые переменные, которые по смыслу можно отнести к некоторой общей группе или классу. Не путать с понятием класса, которым мы оперируем при классификации наших данных. Имеется в виду, что, например, переменные `weights`, `bias`, `z`, `a` (output) между собой связаны, и их можно представить как некие свойства некоторого объекта. То есть наш объект `perceptron` будет сам в себе хранить веса и смещение, например.\n",
    "\n",
    "Так же и с функциями. Например, функция `forward`, которая принимает некоторые данные и вычисляет `z` и `a`, или функция `predict`, которая принимает нашу выборку и передает по отдельности каждый элемент выборки в `forward`, или функцию активации тоже можно отнести к нашему объекту `perceptron`. То есть эти переменные и эти функции как бы связаны между собой и объединены по смыслу с нашим объектом `perceptron`.\n",
    "\n",
    "Поэтому мы создаем общий класс с названием `Perceptron` и \"помещаем\" в него наши переменные, которые мы называем атрибутами, и функции, которые мы называем методами. Когда мы создаем сам объект `perceptron` на основе этого класса, этот объект хранит в себе свои значения переменных и может быть в разные моменты вызван для произведения нужных нам вычислений. При этом этих объектов может быть и несколько, что нам обязательно нужно будет, когда мы столкнемся с тем, что наш один объект класса перцептрон не способен решить некоторые задачи, а вот уже три этих объекта объединенные в сеть, эти задачи решают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Описание атрибутов и методов класса Perceptron\n",
    "\n",
    "`__init__`\n",
    "Инициализирует перцептрон с заданными весами и смещением.\n",
    "weights - начальные веса.\n",
    "bias - начальное значение смещения (по умолчанию None).\n",
    "heaviside(self, z):\n",
    "\n",
    "`heaviside`\n",
    "Функция активации (функция Хевисайда).\n",
    "Возвращает 1, если z >= 0.5, иначе 0.\n",
    "\n",
    "`forward`\n",
    "Функция подает/\"прогоняет\" данные в/через перцептрон, вычисляет взвешенную сумму и применяет функцию активации.\n",
    "Возвращает результат применения функции активации.\n",
    "\n",
    "`predict`\n",
    "Функция предсказывает выходные значения всего набору данных.\n",
    "Возвращает список результатов активации для каждого набора входных значений.\n",
    "\n",
    "`__str__`\n",
    "Возвращает строковое представление объекта перцептрона с текущими значениями атрибутов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Магические методы (дополнитеьное пояснение) \n",
    "\n",
    "У объекта могут быть втроенные или как их еще называют магические методы. В Python они выделяются двумя подчеркиваниями в начале и в конце имени. Например `__new__`, `__init__`, `__call__`, `__srt__` и другие. Эти методы позволяют получать разное поведение объекта в разных условиях/ситуациях. Что это значит? Когда мы создаем объект и пишем строке `perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)` то вызывается метод `__init__` нашего класса Perceptron и ему могут быть переданы два параметра: `weights` и `bias`. Причем `weights` обязательно должен быть указан а `bias` если не укажем то примет значение по-умолчанию `None` (на самом деле перед `__init__` будет вызван магический метод `__new__` но мы его пока не используем). То есть это поведение объекта при создании. Если мы например определили метод `__str__`, то при попытке напечатать наш объект: `print(perceptron)` - вызовется метод `__str__` и мы получим строку которую этот метод возвращает. Методы написанные нами вызываются у объекта путем указания их имени через точку. Например в результате выполнения строки `predictions = perceptron.predict(X)` в переменную `prediction` будет записан результат который вернет метод `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n"
     ]
    }
   ],
   "source": [
    "# Создаем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "# Выводм текстовое представление объекта\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Данные \"прогона\" последнего объекта\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -1.25], bias: 1.75, z: 0.0, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron.predict(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\nДанные \"прогона\" последнего объекта')\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сделаем еще одну мелочь, а именно добавим в наш класс магический метод `__call__`. Особой необходимости в этом нет, но как говорят: для закрепления пройденого материала. После добавления этого магического метода мы сможем подвать данные в наш объект и получать предсказание просто написав такой код: `predictions = perceprton(X)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, inputs):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = inputs\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Данные \"прогона\" последнего объекта\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -1.25], bias: 1.75, z: 0.0, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\nДанные \"прогона\" последнего объекта')\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы оперируем таким понятием как перцептрон и можем также оперировать таким понятием как обучение перцептрона. То есть мы будем в цикле из первоначального кода вызывать наш перцептрон подавая в него данные и получая его предсказания. На основе этих предсказаний мы будем обучать его. Но перед этим добавим еще один метод в наш класс. А именно метод который будет обучать/изменять веса и смещение нашего объекта. Ведь логично что функция которая изменяет параметры самого объекта должна принадлежать этому же объекту. Это конечно не обязательно но вполне логично зачем нам оставлять ее как некую отдельную функцию если эта функция все-равно всегда работает только с этим объектом. Итак перенесем функцию `update` в наш класс и станет методом для обновления весов и смещения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (устанавливаются позже в методе forward)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, h, x):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += h * error * x[i]\n",
    "        self.bias += h * error\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weights: [-0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/5, weights: [-0.5, 0.75], bias: 1.75\n",
      "Эпоха обучения 3/5, weights: [-0.5, 1.75], bias: 1.75\n",
      "Эпоха обучения 4/5, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 5/5, weights: [-1.5, 1.75], bias: 0.75\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [0, 1], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [1, 0], weights: [-1.5, 1.75], bias: 0.75, z: -0.75, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [-1.5, 1.75], bias: 0.75, z: 1.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    for x, y_true in zip(X, y):    \n",
    "        # Прогон каждого отдельного одного объекта из выборки через перцептрон\n",
    "        prediction = perceptron.forward(x)\n",
    "        \n",
    "        # Вычисление ошибки\n",
    "        error = y_true - prediction\n",
    "        \n",
    "        # Обновление/изменение веса и смещения на основе ошибки\n",
    "        perceptron.update(error, h, x)\n",
    "    \n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in perceptron.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(perceptron.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно пока еще не очень понятно зачем все эти абстракции в виде классов, объектов. Кода меньше не стало, процесс обучения в целом не отличается. Какие преимущества? Просто мы пока не усложняли нашу задачу, поэтому и преимущества перехода к ООП пока могут быть не столь очевидны. Но давайте сделаем еще один довольно важный шаг и перенесем весь алгоритм обучения также в наш класс. Ведь обучение тоже напрямую относится к нашему перцептрону. Именно поэтому я и назвал главу \"Почти Перцептрон\". После реализации процесса обучения в самом классе можно сказать что у нас уже полноценный Перцептрон. Это разделение на почти перцептрон и полноценный перцептрон довольно условное. В целом нет какого-то правила что считать полноценным, а что неполноценным перцептроном. Да и в целом многие понятия довольно абстракты и условны. Я сделал такое разделение просто для постепенного продвижения от простого к более сложному. И в дальнейшем, например, мы вообще уберем метод обучения из класса нейрона на основе которого будем строить нейронную сеть, потому что метод обучения будет принадлежать такому классу как нейронная сеть а не каждому объекту нейрона в этой сети. Да и в целом мы несколько уйдем от такого понятия как нейрон. Такой класс нам не нужен будет в том виде в котором мы его реализуем сейчас. Потому что все вычисления будут происходить на уровне таких понятий как \"слой нейронной сети\". Но обо всем по-порядку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перенесем в наш класс метод для обучения перцептрона и решим уже наконец вполне конкретную задачу которая называется \"Логическое И (AND)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "        # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, learning_rate):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += learning_rate * error * self.inputs[i]\n",
    "        self.bias += learning_rate * error\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = y_true - prediction\n",
    "                \n",
    "                # Обновление/изменение веса и смещения на основе ошибки\n",
    "                self.update(error, learning_rate)\n",
    "            \n",
    "            # Отладочная информация\n",
    "            rounded_weights = [round(weight, 2) for weight in self.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "            rounded_bias = round(self.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "            print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Логическое И (AND)\n",
    "\n",
    "Что такое \"Логическое И\"? Возможно объяснение, что это такое тут не требуется, так как с этого начинается практический любой нормальный курс по программированию, но все же еще раз вспомним что это такое и дадим пояснения в контексте нейронных сетей.\n",
    "Задача \"Логическое И\" (AND) заключается в создании логической функции, которая возвращает 1 (истина), только если оба входных значения равны 1. В остальных случаях функция возвращает 0 (ложь).\n",
    "\n",
    "Таблица истинности для операции логического И:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        0        |\n",
    "|   1    |   0    |        0        |\n",
    "|   1    |   1    |        1        |\n",
    "\n",
    "В контексте нейронных сетей можно сказать, что, другими словами, мы имеем четыре объекта в нашей выборке. У каждого объекта по два признака (Вход A и Вход B). И каждый объект отнесен к одному из двух классов (Выход). Задача состоит в том чтобы обучить наш перцептрон так, чтобы подавая в него каждый из объектов (каждый набор признаков объекта) наш перцептрон его бы относил к правильному классу. Возможно ли научить этому перцептрон?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 0, 0, 1]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [1.5, -0.25], bias: 0.75\n",
      "Эпоха обучения 3/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 4/10, weights: [2.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 5/10, weights: [2.5, 0.75], bias: -1.25\n",
      "Эпоха обучения 6/10, weights: [2.5, 1.75], bias: -1.25\n",
      "Эпоха обучения 7/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 8/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 9/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 10/10, weights: [2.5, 0.75], bias: -2.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [0, 0, 0, 1], ожидаемые/истинные значения: [0, 0, 0, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [2.5, 0.75], bias: -2.25, z: -2.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [0, 1], weights: [2.5, 0.75], bias: -2.25, z: -1.5, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 0], weights: [2.5, 0.75], bias: -2.25, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [2.5, 0.75], bias: -2.25, z: 1.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 0, 0, 1]  # объекты c признаками [0, 0], [0, 1] и [1, 0] принадлежат классу 0, объект с признаком [1, 1] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=1)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что наш перцептрон научисля решать задачу \"Логическое И\". Касательно кода можно заметить, что мы перенесли метод обучения перцептрона непосредственно в класс Perceptron, перименовали переменную `h` в `learning_rate` и так как у нас каждый набор признаков записывается в методе `forward` в переменную `self.inputs` то мы можем в метод `update` не передавать текущий `x` а просто брать эти значения из `self.inputs`. Можно было так же сделать и с learning_rate, но в будущем мы все равно перенесем этот параметр в другой объект класса Optimaizer, поэтому пока оставим так как есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Логическое ИЛИ (OR)\n",
    "\n",
    "Перед тем как сделать следующий шаг давайте рассмотрим еще парочку задач. Первая из них это \"Логичексое ИЛИ (OR)\". Тут принцип абсолютно такой же как и в прошлой задаче за исключением того что \"Логическое ИЛИ\" возвращает истину (1), если хотя бы один из входов истинен. Если оба входа ложны (0), то результатом будет ложь (0).\n",
    "\n",
    "Таблица истинности для операции логического ИЛИ:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        1        |\n",
    "|   1    |   0    |        1        |\n",
    "|   1    |   1    |        1        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 1, 1, 1]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 3/10, weights: [0.5, -0.25], bias: 0.75\n",
      "Эпоха обучения 4/10, weights: [0.5, 0.75], bias: 0.75\n",
      "Эпоха обучения 5/10, weights: [1.5, 0.75], bias: 0.75\n",
      "Эпоха обучения 6/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 7/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 8/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 9/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 10/10, weights: [1.5, 0.75], bias: -0.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [0, 1, 1, 1], ожидаемые/истинные значения: [0, 1, 1, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [1.5, 0.75], bias: -0.25, z: -0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [0, 1], weights: [1.5, 0.75], bias: -0.25, z: 0.5, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [1, 0], weights: [1.5, 0.75], bias: -0.25, z: 1.25, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [1, 1], weights: [1.5, 0.75], bias: -0.25, z: 2.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1, 1, 1]  # объект c признаком [0, 0] принадлежат классу 0, объекты с признаками [0, 1], [1, 0] и [1, 1] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=1)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, наш перцептрон вполне способен решить задачу логического ИЛИ. И тут мы подходим к интересному моменту. А именно, вернемся к началу. Как можно узнать из различных источников, перцептрон был изобретён в 1957 году Фрэнком Розенблаттом. Это была одна из первых моделей искусственного интеллекта. Вот краткая хронология событий, связанных с перцептроном:\n",
    "\n",
    "**Изобретение и начальные успехи (1957):**\n",
    "- Фрэнк Розенблатт разработал перцептрон, который являлся первой моделью нейрона, способной к обучению.\n",
    "- В 1958 году на перцептроне была проведена демонстрация на IBM 704, вызвавшая значительный интерес в научных кругах и прессе.\n",
    "- В начале 1960-х годов Розенблатт получил финансирование от ВМС США для разработки аппаратной реализации перцептрона, называемой Mark I Perceptron.\n",
    "\n",
    "**Критика и ограничения (1969):**\n",
    "- В 1969 году Марвин Минский и Сеймур Пейперт опубликовали книгу \"Perceptrons\", в которой описали ограничения перцептрона, такие как невозможность решения задачи XOR и других нелинейно разделимых задач.\n",
    "- Их работа показала, что перцептрон не может обрабатывать нелинейные зависимости, что привело к значительному снижению интереса к исследованиям в области нейронных сетей на несколько лет.\n",
    "\n",
    "История также отмечает, что Фрэнк Розенблатт умер в 1971 году в возрасте 43 лет. Хотя его смерть не была основной причиной остановки развития нейронных сетей, она совпала с рядом других факторов, приведших к периоду, известному как \"AI зима\". Это был период снижения интереса и финансирования в области искусственного интеллекта, вызванный завышенными ожиданиями, техническими ограничениями и критическими публикациями. Кстати, стоит отметить, что Розенблатт не утверждал, что перцептрон может решить любые задачи, но сеть из нескольких перцептронов вполне способна решить задачу XOR. Однако, как говорится, ~~AI~~ зима близко.\n",
    "\n",
    "Если нарисовать на графике четыре точки `[[0, 0], [0, 1], [1, 0], [1, 1]]` задачи логического И и просто посмотреть на этот график, то можно легко понять, как эти точки разделить одной прямой линией так, чтобы по одну сторону линии оказались точки одного класса, а по другую — точки другого класса. То же самое можно сделать и для задачи логического ИЛИ. Однако для задачи исключающего ИЛИ (XOR) такую разделительную линию уже невозможно провести. Один перцептрон не способен решить такую задачу, то есть не может правильно классифицировать все точки. Давайте проверим это."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Исключающее ИЛИ (XOR) и однослойный перцептрон\n",
    "\n",
    "XOR (Exclusive OR) - это логическая операция, которая выдает значение истина (1) тогда и только тогда, когда один из входов равен истине (1), а другой равен лжи (0). В отличие от логических операций AND и OR, задача XOR не является линейно разделимой, что делает ее интересной и сложной для ранних нейронных сетей, таких как однослойные перцептроны.\n",
    "\n",
    "Таблица истинности для операции исключающего ИЛИ:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        1        |\n",
    "|   1    |   0    |        1        |\n",
    "|   1    |   1    |        0        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 1, 1, 0]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -1.0], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [-0.5, -1.0], bias: 1.5\n",
      "Эпоха обучения 3/10, weights: [-0.5, -0.75], bias: 1.5\n",
      "Эпоха обучения 4/10, weights: [-0.5, -0.75], bias: 1.25\n",
      "Эпоха обучения 5/10, weights: [-0.5, -0.5], bias: 1.25\n",
      "Эпоха обучения 6/10, weights: [-0.5, -0.5], bias: 1.0\n",
      "Эпоха обучения 7/10, weights: [-0.5, -0.25], bias: 1.0\n",
      "Эпоха обучения 8/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "Эпоха обучения 9/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "Эпоха обучения 10/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 0, 0, 0], ожидаемые/истинные значения: [0, 1, 1, 0]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [-0.5, -0.5], bias: 0.75, z: 0.75, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [0, 1], weights: [-0.5, -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 0], weights: [-0.5, -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -0.5], bias: 0.75, z: -0.25, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1, 1, 0]  # объекты c признаками [0, 0] и [1, 1] принадлежат классу 0, объекты с признаками [0, 1] и [1, 0] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=0.25)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько бы мы не подбирали/обучали веса мы не решим эту задачу одним перцептроном. Но эта задача вполне себе решается многослойным перцептроном. \n",
    "\n",
    "Следующим шагом было бы логично реализовать некий класс для слоя и класс этой самой многослойной сети из перцептронов и убедится, что задача XOR да и многие другие линейно неразделимые объекты можно правльно классифицировать с помощью MLP (многослойного перцептрона), но это просто потеря времени на мой взгляд. Так как перцептрон хоть и можно считать прародителем нейрона, но по сути это всего лишь частный случай \"обычного\" нейрона просто с пороговой/ступенчатой функцией активации, ну или линейной активацией как говорит Википедия. Давайте просто перейдем к понятию нейрон и на нем уже построим нейронную сеть, а потом в качестве примера решим задачу XOR в том числе и на перцептроне. И сможем кстати сразу увидеть разницу и преимущества нейрона над перцептроном.\n",
    "\n",
    "Итак в целом нейрон это тоже самое что и перцептрон. И работает и обучается точно так же. И сеть на нейронах выглядит так же. Хотя, повторюсь, понятие нейрон тоже довольно условное. Как я уже говорил в keras вообще нет такого понятия как нейрон. Там все вычисления происходят в слоях которые представлены в виде матриц и отдельно понятие нейрон никак не выделяется. Но пака мы все равно напишем класс Neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Нейрона\n",
    "class Neuron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None, activation=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = activation        # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "        # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, learning_rate):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += learning_rate * error * self.inputs[i]\n",
    "        self.bias += learning_rate * error\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = y_true - prediction\n",
    "                \n",
    "                # Обновление/изменение веса и смещения на основе ошибки\n",
    "                self.update(error, learning_rate)\n",
    "            \n",
    "            # Отладочная информация\n",
    "            rounded_weights = [round(weight, 2) for weight in self.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "            rounded_bias = round(self.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "            print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
