{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# С чего все началось\n",
    "\n",
    "Для ознакомления с тем, что такое перцептрон, да и в целом как все начиналось, можно почитать статью на Википедии. Там представлена краткая история, довольно подробное объяснение, и в целом всё, что нам потребуется, и даже больше. В статье, помимо прочего, в разделе \"Историческая классификация\" говорится следующее:\n",
    "\n",
    "*\"Понятие перцептрона имеет интересную, но незавидную историю. В результате неразвитой терминологии нейронных сетей прошлых лет, резкой критики и непонимания задач исследования перцептронов, а иногда и ложного освещения прессой, изначальный смысл этого понятия исказился.\"*\n",
    "\n",
    "И далее:\n",
    "\n",
    "*Сравнивая разработки Розенблатта и современные обзоры и статьи, можно выделить 4 довольно обособленных класса перцептронов:*\n",
    "\n",
    "1. **Перцептрон с одним скрытым слоем**: классический перцептрон, описанный в книгах Розенблатта. Содержит по одному слою S-, A- и R-элементов.\n",
    "2. **Однослойный перцептрон**: простейшая сеть прямого распространения с входами, напрямую соединёнными с выходами. Это линейный классификатор, который не может решать задачи с нелинейными зависимостями, такие как XOR.\n",
    "3. **Многослойный перцептрон (по Розенблатту)**: перцептрон с дополнительными слоями A-элементов. Анализировался Розенблаттом в его книге.\n",
    "4. **Многослойный перцептрон (по Румельхарту)**: включает дополнительные слои A-элементов и обучается методом обратного распространения ошибки. Является расширением перцептрона Розенблатта.\n",
    "\n",
    "Также полезно будет ознакомиться с разделами \"Алгоритмы обучения\" и \"Традиционные заблуждения\". Пересказывать всю статью не вижу смысла. Разбирать подробно различные реализации и писать для них код также не имеет смысла, так как с тех пор многое изменилось, хотя путаница в терминологии тех лет, на мой взгляд, всё ещё остаётся. Лично для себя я выделил несколько понятий, которые на мой взгляд являются ключевыми. Эти понятия я и собираюсь разобрать, и на их основе писать свою реализацию нейронной сети.\n",
    "\n",
    "Итак, по порядку:\n",
    "\n",
    "1. **Перцептрон/нейрон (однослойный перцептрон)**: простейшая сеть прямого распространения с входами, напрямую соединёнными с выходами. Это линейный классификатор, который не может решать задачи с нелинейными зависимостями, такие как XOR. Для простоты такой объект я буду называть перцептроном или нейроном.\n",
    "2. **Нейронная сеть (многослойный перцептрон)**: включает дополнительные слои и обучается методом обратного распространения ошибки. Является расширением перцептрона Розенблатта. Для простоты это я буду называть нейронной сетью.\n",
    "3. **Общий алгоритм обучения**: обучение с учителем, метод обратного распространения ошибки.\n",
    "\n",
    "Эти три пункта я взял за основу, и вокруг них будет написан весь код. Как видите, по сравнению со статьей на Википедии, я значительно всё упростил, но, забегая вперед, скажу, что в финальной реализации нам даже такое, казалось бы, основное понятие как нейрон не особенно будет нужно, потому что все вычисления будут происходить на уровне слоев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Еще не Перцептрон\n",
    "\n",
    "**Краткое вступление о том, что такое перцептрон.**\n",
    "\n",
    "Перцептрон был изобретён в 1957 году Фрэнком Розенблаттом, американским психологом и специалистом по нейронным сетям. Он разработал перцептрон как алгоритм машинного обучения, который может классифицировать входные данные на основе их линейных свойств. Перцептрон представлял собой одну из первых моделей искусственного нейрона, способную к обучению и распознаванию образов. Таким образом, перцептрон можно кратко описать как алгоритм для классификации данных. Давайте попробуем создать такой алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Общий алгоритм (обучение с учителем)\n",
    "\n",
    "Начну не с самого перцептрона, а с общего алгоритма задачи. Тут, на самом деле, можно придраться и сказать что перцептрон это и есть алгоритм. Повторюсь, что тут присутствует некоторая путанница. Переводится перцептрон с английского как восприятие. То есть это в принципе некое понятие которое моделирует процесс человеческого восприятия. В той же Википедии есть описание перцептрона так его описывал Розенблатт, а так же различные виды перцептрона и прочее. Я же выбрал однослойный перцептрон который фактически является формальным нейроном. Предположим, что у нас есть какие-то данные, которые мы назовём входными данными (сигналами). Также мы знаем, каким должен быть результат — назовём его выходными данными. Наша задача — написать программу, которая будет получать на входе эти данные, затем производить над ними определённые вычисления (сложение/умножение входных данных на некоторые заданные значения) и выдавать ответ. Если этот ответ не соответствует ожидаемому, программа должна изменить некоторые из своих параметров, чтобы ответы совпадали.\n",
    "\n",
    "Кажется запутанным? На самом деле, всё гораздо проще, чем может показаться на первый взгляд. По сути, нам нужно найти решение уравнения путём \"подбора\"/изменения некоторых его переменных. Эти переменные можно назвать коэффициентами, или, как их общепринято называть, весами и смещением."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weight: -2.75, output: -2.75, prediction: 0\n",
      "Эпоха обучения 2/5, weight: -1.75, output: -1.75, prediction: 0\n",
      "Эпоха обучения 3/5, weight: -0.75, output: -0.75, prediction: 0\n",
      "Эпоха обучения 4/5, weight: 0.25, output: 0.25, prediction: 1\n",
      "Эпоха обучения 5/5, weight: 0.25, output: 0.25, prediction: 1\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм (обучение с учителем)\n",
    "\n",
    "# Входные данные (x) и целевая метка (y) (ожидаемый результат)\n",
    "x = 1\n",
    "y = 1\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения веса и смещения в процессе обучения\n",
    "\n",
    "# Вес и смещение\n",
    "weights = -2.75  # начальные веса (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "print(f'Процесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Вычисление взвешенной (weight) суммы входного сигнала (x)\n",
    "    z = x * weights\n",
    "    \n",
    "    # Активация\n",
    "    prediction = 1 if z > 0 else 0\n",
    "    \n",
    "    # Отладочная информация\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weight: {weights:.2f}, output: {z:.2f}, prediction: {prediction}')\n",
    "\n",
    "    # Обновление/изменение весов\n",
    "    if prediction != y:\n",
    "        if prediction == 0:\n",
    "            weights += x\n",
    "        if prediction == 1:\n",
    "            weights -= x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Код выше демонстрирует общий алгоритм обучения. Конечно, на самом деле, алгоритм обучения нейронной сети несколько сложнее, но в целом похож. В коде пока нет никакой сети и даже нет никаких нейронов или перцептронов, а также отсутствует одна из важнейших концепций, такая как МОР (метод обратного распространения ошибки). Однако, в нем есть такие понятия как вычисление взвешенной суммы, активация и обучение весов. В целом, код демонстрирует общий алгоритм того, что происходит при обучении.\n",
    "\n",
    "Код написан специально максимально упрощенно, без использования массивов, матриц, сторонних библиотек, функций, ООП и других сложных концепций. Все это будет добавляться постепенно. В конце у нас будет полноценная реализация нейронной сети со слоями и нейронами на основе объектов и классов, с множеством различных функций и даже небольшим ~~костылем~~ классом для Keras, с помощью которого мы сможем сравнить результаты работы нашей простой нейронной сети с результатами, которые выдает аналогичная нейронная сеть, построенная на Keras.\n",
    "\n",
    "Общие понятия и терминология:\n",
    "1. **Входные данные (`x`)**:\n",
    "   - Набор данных, подаваемый на вход модели (сети/слоя/нейрона) для обучения или предсказания. Обычно представляется в виде матрицы, где строки соответствуют примерам, а столбцы — признакам. Мы пока будем пользоваться списками в котороых каждый элемент это значение некоторго параметра объекта или фича от английского features. В примере у нас в качестве входных данных был просто объект с одним признаком `x = 1`. \n",
    "   \n",
    "2. **Целевая метка (`y`)**:\n",
    "   - Значения, которые модель должна предсказать. В задаче классификации это могут быть классы, а в задаче регрессии — числовые значения.\n",
    "   \n",
    "3. **Вес(а) (`weights`)**:\n",
    "   - Параметры модели, которые обучаются в процессе тренировки. Влияние каждого признака на итоговое предсказание регулируется весами. В примере был всего один вес так как у нас всего один входной сигнал `x = 1`.\n",
    "\n",
    "4. **Смещение (`bias`)**:\n",
    "   - Дополнительный параметр модели, который помогает лучше подгонять модель под данные. Он позволяет модели предсказывать ненулевые значения, даже если все входные признаки равны нулю. В примере не использовался.\n",
    "   \n",
    "5. **Значение `z` (значение функции или вычисленное значение взвешенной суммы входных данных и смещения)**:\n",
    "   - Промежуточное значение, вычисляемое как линейная комбинация входных данных и весов, с добавлением смещения.\n",
    "   - Формула: `z = x * weights + bias`. В примере не было смещения.\n",
    "\n",
    "6. **Функция активации (activation function или просто `activation`)**:\n",
    "   - Функция, применяемая к промежуточному значению `z`, чтобы ввести нелинейность в модель и помочь ей решать сложные задачи.\n",
    "   - Пример: `ReLU (Rectified Linear Unit)`, `sigmoid`, `tanh`. У перцептрона который мы создадим ступенчатая функция активации которая называется часто `heaviside`.\n",
    "\n",
    "7. **Предсказание (`prediction`)**:\n",
    "    - Значение, которое модель возвращает после обработки входных данных (вычисление взвешенной суммы и активация). В идеале оно должно совпадать с истинном значением (`y`). В задаче классификации, например, это может быть класс, к которому, по мнению модели, относится входной пример."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Разбор результата алгоритма обучения\n",
    "\n",
    "Итак, давайте разберём и сразу же улучшим наш код. На самом деле, задача, которую мы решаем выше, довольно бесполезная и не имеет практического смысла. Повторюсь, она лишь демонстрирует алгоритм обучения нейрона/перцептрона. То есть она показывает, что алгоритм получает входные данные, производит с ними определённые операции (сложение/умножение), сравнивает результат с тем, который мы задали как правильный, и если ответ не совпадает, алгоритм корректирует вес в нужную сторону так, чтобы ответ совпадал с верным.\n",
    "\n",
    "Изначально мы задали вес как: `weight = -2.75`. Значения весов перед обучением выбираются случайным образом. И мы хотим чтобы наш перцептрон от этих случайных весов перешел к весам которые бы решали нашу задачу. Наши входные данные были просто одним числом: `x = 1`, и мы сказали, что правильный ответ должен быть равен `y = 1`. Наша функция вычисления `y` выглядит так: `output = x * weight`. `output` — это не совсем то что мы получаем на выходе, просто пока используем такое название. Так вот, дальше мы применяем функцию активации к `output`, а именно, проверяем если `output > 0` то считаем что мы предсказали 1, а если `output <= 0`, то счиатем что мы предсказали 0. Получается: `output = 1 * (-2.75) = -2.75`. Предсказание `prediction = 0`, так как `-2,75 < 0`. Так как ответ не сошелся, то проверяем `prediction == 0`, если да, то увеличиваем веса, `weight += 1`, Вес станет -1.75.\n",
    "\n",
    "Первая эпоха завершена. Теперь у нас `weight = -1.75`. Какой же теперь `output`? `output = -1.75 * 1 = -1.75`. Напомню, что при начальных значениях веса `output` был `-2.75`. Мы видим, что результат стал ближе к правильному, но пока `output <= 0` наша активация все равно возвращает 0, что не соответствует правильному ответу. Но мы указали 5 эпох для обучения, поэтому начинаем вторую. Можете сами подставить вес в формулу `output = x * weight`, посчитать результат, и убедиться в том, что наш вес станет: `weight = -0.75`. Теперь `output = 1 * (-0.75) = -0.75`, то есть ещё ближе к нашему правильному ответу. Проделав все 5 эпох обучения мы еще приблизимся к нашему правильному ответу. На самом деле уже на 4 эпохе мы получим правильный ответ. И далее можно было бы остановить обучение проверив что ответ соответствует, но мы проделаем еще одну эпоху и убедимся, что если ответ правильный, то у нас веса перестают обучаться."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Выводы\n",
    "\n",
    "Как было сказано, наш код демонстрирует общий алгоритм обучения и объясняет некоторые базовые понятия вроде входные данные, целевая метка, вес, активация и прочее. Так как стояла задача продемонстировать общий процесс обучения, то многие деталти были упущены для упрощения и пример, в целом, не имеет никакго практического смысла. Подобные примеры наглядно демонстрируют основные понятия и общие принцыпы. Перед тем как перейти к более осмысленным примерам посмотрим как бы повел себя алгоритм если бы целевая метка была 0, а не 1 (`y = 0`), но с добавлением смещения и некоторыми изменениями в формуле изменения весов и смещения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weight: -2.75, bias: 5.25, output: 2.50, prediction: 1, error: -1\n",
      "Эпоха обучения 2/5, weight: -3.75, bias: 4.25, output: 0.50, prediction: 1, error: -1\n",
      "Эпоха обучения 3/5, weight: -4.75, bias: 3.25, output: -1.50, prediction: 0, error: 0\n",
      "Эпоха обучения 4/5, weight: -4.75, bias: 3.25, output: -1.50, prediction: 0, error: 0\n",
      "Эпоха обучения 5/5, weight: -4.75, bias: 3.25, output: -1.50, prediction: 0, error: 0\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм (обучение с учителем)\n",
    "\n",
    "# Входные данные (x) и целевая метка (y) (ожидаемый результат)\n",
    "x = 1\n",
    "y = 0\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения веса и смещения в процессе обучения\n",
    "\n",
    "# Вес и смещение\n",
    "weights = -2.75  # начальный вес (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 5.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "print(f'Процесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Вычисление взвешенной (weight) суммы входного сигнала (x) и смещения (bias)\n",
    "    z = x * weights + bias  # это то, что выдает/предсказывает наш алгоритм\n",
    "    \n",
    "    # Активация\n",
    "    prediction = 1 if z > 0 else 0\n",
    "    \n",
    "    # Вычисление ошибки\n",
    "    error = y - prediction\n",
    "\n",
    "    # Отладочная информация\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weight: {weights:.2f}, bias: {bias:.2f}, output: {z:.2f}, prediction: {prediction}, error: {error}')\n",
    "\n",
    "    # Обновление/изменение веса и смещения на основе ошибки error\n",
    "    weights += error * x\n",
    "    bias += error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы видим, что изначально у нас было предсказание 1 а мы ожидали 0. Используя ошибку предсказания мы немного подкоррестировали вес и смещение и получили уже на третьей эпохе нужный результат. В примере так же видно как обучается наше смещение.\n",
    "\n",
    "Общие понятия и терминология:\n",
    "1. **Ошибка (`error`)**:\n",
    "   - Разница между предсказанным значением и реальной целевой меткой. Это еще не та ошибка, которая используется для оценки качества модели. Пока это просто для того, чтобы понять, нужно уменьшать или увеличивать веса и смещение. Ошибка которая может нам помочь оценить качество предсказаний это, например, MSE (Mean Squared Error) и пока мы ее не используем. Так же можно заметить, что мы вычисляем ошибку как `y - prediction`, а в первом предложении говорится, что это разница `prediction - y`. На самом деле это не принципиально. Просто мы пользуемся `y - prediction` так как это интуитивно более понятно. Но мы можем так же пользоватьмся и `prediction - y` просто тогда мы должны менять веса не `weights +=` а `weights -=`. Пока мы будем пользоваться только понятием `error` и для упрощения считать ошибку как `y - prediction`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Описание процесса подготовки и обучения нейронной сети\n",
    "\n",
    "1. **Подготовка данных**: Определяем входные данные `X` или просто один пример `x` и целевые метки `y`.\n",
    "\n",
    "2. **Инициализация модели**: Устанавливаем начальные значения весов и смещений.\n",
    "\n",
    "3. **Метод/процесс прямого распространения (Forward Pass)**:\n",
    "   - \"Подаем\" наши данные в сеть/нейрон. \n",
    "   - Вычисляем промежуточное значение `z` для всех нейпонов/слов сети или просто для одного нейрона.\n",
    "   - Применяем функцию активации к `z`, получая `a` (`output`).\n",
    "\n",
    "4. **Вычисление ошибки**:\n",
    "   - Сравниваем значение активированного выхода `a` (`output`) с истинным значением `y`.\n",
    "   - Используем функцию потерь для расчета ошибки. Пока просто будем использовать значение `error`.\n",
    "\n",
    "5. **Метод/процесс обратного распространения (Backward Pass)**:\n",
    "   - Вычисляем градиенты функции потерь по отношению к весам и смещениям на выходном слое/нейроне. Вот тут мы пока не будем пользоваться понятием градиент и производная. Да и в целом пока мы не перейдем непосредственно к сети из слоев с нейронами мы не будем называть это методом обратного распространения ошибки (МОР), так как она (ошибка) пока еще не распространияется у нас, то есть не передается в предыдущие слои сети.\n",
    "   - Обновляем веса и смещения с использованием алгоритма оптимизации, например, градиентного спуска. Тут туже пока несколько упростим процесс и не будем применять понятие \"алгоритм оптимизации\" опять же для упрощения на начальных этапах.\n",
    "\n",
    "6. **Повторение**:\n",
    "   - Повторяем шаги 3-5 на протяжении заданного количества эпох или до достижения приемлемого уровня ошибки.\n",
    "\n",
    "7. **Предсказание**:\n",
    "   - После обучения модели, подаем новые данные на вход и получаем предсказание. Так как для начала мы не будем использовать большие выборки которые должны быть разделены на обучающую и тестовую, то проедсказывать мы будем то на чем обучались. Это не совсем правильно, но, опять же, зависит от задачи.\n",
    "\n",
    "В итоге хочется сказать, что некоторые неточности в терминологии допущены вынужденно/намерено для общего упрощения понимания задачи. В дальнейшем все эти неточности будут естесственным образом исправлены.\n",
    "\n",
    "Итак давайте перейдем от задачи которая в принципе имела мало смысла к чему-то более осмысленному. А именно давайте теперь рассмотрим некий один объект `x` нашей некой выборки `X`, у которого есть два признака. Те есть `x = [1, 0]`. Перепишем наш код с учетом той терминологии что мы описали выше, также обобщим формулу вычисления `z`, и добавим еще функций. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weights: [-0.5, -1.25], bias: 5.25, prediction: 1, error: -1\n",
      "Эпоха обучения 2/5, weights: [-1.5, -1.25], bias: 4.25, prediction: 1, error: -1\n",
      "Эпоха обучения 3/5, weights: [-2.5, -1.25], bias: 3.25, prediction: 1, error: -1\n",
      "Эпоха обучения 4/5, weights: [-3.5, -1.25], bias: 2.25, prediction: 0, error: 0\n",
      "Эпоха обучения 5/5, weights: [-3.5, -1.25], bias: 2.25, prediction: 0, error: 0\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "x = [1, 0]  # объект с двумя признаками\n",
    "y = 0\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 5  # количество итераций для изменения весов и смещения в процессе обучения\n",
    "\n",
    "# Веса и смещение\n",
    "weights = [-0.5, -1.25]  # начальные веса (эти параметры мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 5.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Функция активации: ступенчатая/пороговая функция\n",
    "def activation(z):\n",
    "    return 1 if z > 0 else 0\n",
    "\n",
    "# Функция предсказания\n",
    "def predict(x):\n",
    "    # z = x1*w1 + x2*w2 + ... + xn*wn + bias\n",
    "    z = sum(xi * wi for xi, wi in zip(x, weights)) + bias  # взвешенная сумма\n",
    "    a = activation(z)  # активация\n",
    "    return a  # возвращаем значение активации (prediction)\n",
    "\n",
    "# Функция обновления/изменения весов и смещения на основе ошибки\n",
    "def update(weights, bias, error, x):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] += error * x[i]\n",
    "    bias += error\n",
    "    return weights, bias\n",
    "\n",
    "print(f'Процесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    # Получение предсказания\n",
    "    prediction = predict(x)\n",
    "    \n",
    "    # Вычисление ошибки\n",
    "    error = y - prediction\n",
    "    \n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}, prediction: {prediction}, error: {error}')\n",
    "\n",
    "    # Обновление/изменение весов и смещения на основе ошибки\n",
    "    weights, bias = update(weights, bias, error, x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В целом нет смысла разбирать всё повторно, так как разбор аналогичен предыдущему. Главное — понять, что объекты `x`, подаваемые в сеть, будут иметь свои признаки, и сеть должна обучить веса таким образом, чтобы правильно классифицировать эти объекты (в случае задачи классификации). На что можно обратить внимание, так это на то, что, как видно из результатов, наш второй вес не обучается. Это происходит потому, что наш единственный объект `x` имеет два признака, и один из них равен 0. Поэтому при расчёте изменения второго веса происходит умножение на 0, и, следовательно, второй вес остаётся неизменным. \n",
    "\n",
    "В следующем шаге хотелось бы перейти к ООП и представить всю модель сети как совокупности взаимодействующих между собой объектов (нейронов, слоёв, оптимизаторов и других). Но перед тем как это сделать, сделаем ещё один небольшой шажок: добавим в наш набор ещё один признак и посмотрим на процесс обучения, чтобы окончательно закрепить понимание того, что происходит при обучении."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Почти Логическое И (AND)\n",
    "\n",
    "Что такое \"Логическое И (AND)\" и как наш Перцептрон (нейрон с пороговой функцией активации) решает эту задачу, мы подробно рассмотрим далее. Перед окончательным переходом к ООП давайте кратко рассмотрим ещё один пример, о котором было сказано ранее. Прежде чем писать класс для Перцептрона, проанализируем выборку из двух объектов и посмотрим на процесс обучения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Тест до обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 1, ожидаемое/истинное значение: 0\n",
      "Для входных данных [1, 1] предсказанное значение: 0, ожидаемое/истинное значение: 1\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -2.25], bias: 3.25\n",
      "Эпоха обучения 2/10, weights: [-0.5, -1.25], bias: 3.25\n",
      "Эпоха обучения 3/10, weights: [-0.5, -0.25], bias: 3.25\n",
      "Эпоха обучения 4/10, weights: [-1.5, -0.25], bias: 2.25\n",
      "Эпоха обучения 5/10, weights: [-1.5, 0.75], bias: 2.25\n",
      "Эпоха обучения 6/10, weights: [-1.5, 1.75], bias: 2.25\n",
      "Эпоха обучения 7/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "Эпоха обучения 8/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "Эпоха обучения 9/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "Эпоха обучения 10/10, weights: [-2.5, 1.75], bias: 1.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [1, 0] предсказанное значение: 0, ожидаемое/истинное значение: 0\n",
      "Для входных данных [1, 1] предсказанное значение: 1, ожидаемое/истинное значение: 1\n"
     ]
    }
   ],
   "source": [
    "# Общий алгоритм\n",
    "\n",
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Гиперпараметры (этими параметрами мы можем влиять на процесс обучения)\n",
    "epochs = 10  # количество итераций для изменения весов и смещения в процессе обучения\n",
    "\n",
    "# Веса и смещение\n",
    "weights = [-0.5, -3.25]  # начальные веса (эти параметры мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "bias = 3.25  # начальное смещение (этот параметр мы будем \"тренировать\"/изменять в процессе обучения)\n",
    "\n",
    "# Функция активации: ступенчатая/пороговая функция (порог 0.5)\n",
    "def activation(z):\n",
    "    return 1 if z > 0 else 0\n",
    "\n",
    "# Функция предсказания\n",
    "def predict(x):\n",
    "    # z = x1*w1 + x2*w2 + ... + xn*wn + bias\n",
    "    z = sum(xi * wi for xi, wi in zip(x, weights)) + bias  # взвешенная сумма\n",
    "    a = activation(z)  # активация\n",
    "    return a  # возвращаем значение активации (prediction)\n",
    "\n",
    "# Функция обновления/изменения весов и смещения на основе ошибки\n",
    "def update(weights, bias, error, x):\n",
    "    for i in range(len(weights)):\n",
    "        weights[i] += error * x[i]\n",
    "    bias += error\n",
    "    return weights, bias\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест до обучения')\n",
    "for x, y_true in zip(X, y):\n",
    "    prediction = predict(x)\n",
    "    print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y_true}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    for x, y_true in zip(X, y):    \n",
    "        # Получение предсказания\n",
    "        prediction = predict(x)\n",
    "        \n",
    "        # Вычисление ошибки\n",
    "        error = y_true - prediction\n",
    "\n",
    "        # Обновление/изменение веса и смещения на основе ошибки\n",
    "        weights, bias = update(weights, bias, error, x)\n",
    "\n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "for x, y_true in zip(X, y):\n",
    "    prediction = predict(x)\n",
    "    print(f'Для входных данных {x} предсказанное значение: {prediction}, ожидаемое/истинное значение: {y_true}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В отличии от предыдущего примера, можно заметить, что в процессе обучения обучаются уже оба веса и смещение. Таким образом наша программа с изначальными весами неправильно классифицировала оба объекта, но после 7 эпох обучения веса и смещение были подстроены так, что оба объекта стали классифицироваться правильно."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Почти Перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почему почти станет понятно чуть дальше. Пока давайте разберем код для класса Perceptron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        \"\"\"\n",
    "        Инициализирует перцептрон с заданными весами и смещением.\n",
    "        \n",
    "        :param weights: Список начальных весов.\n",
    "        :param bias: Начальное значение смещения. По умолчанию None.\n",
    "        \"\"\"\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        \"\"\"\n",
    "        Пороговая функция активации (функция Хевисайда).\n",
    "        \n",
    "        :param z: Взвешенная сумма входов и смещения.\n",
    "        :return: 1, если z >= 0.5, иначе 0.\n",
    "        \"\"\"\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        Подает/\"прогоняет\" данные в/через перцептрон, вычисляет взвешенную сумму и применяет функцию активации.\n",
    "        \n",
    "        :param inputs: Список входных значений (набор признаков объекта).\n",
    "        :return: Результат применения функции активации.\n",
    "        \"\"\"\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = inputs\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Подает/\"прогоняет\" весь набор данных в/через перцептрон.\n",
    "        \n",
    "        :param X: Список списков или массив входных значений (набор признаков объекта).\n",
    "        :return: Список результатов активации для каждого набора входных значений (для каждого объекта из выборки).\n",
    "        \"\"\"\n",
    "        return [self.forward(x) for x in X]\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        \"\"\"\n",
    "        Возвращает строковое представление объекта перцептрон.\n",
    "        \n",
    "        :return: Строка с текущими значениями атрибутов перцептрона (значениями атрибутов рассчитанные при последнем \"прогоне\").\n",
    "        \"\"\"\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перед нами класс с названием `Perceptron`. Для чего он нужен? Он нужен для создания разных объектов этого класса. Что такое объект? Тут приходит на ум только бессмысленное объяснение, вроде того, что объект это объект. Так как это не курс по ООП, я попытаюсь объяснить только общие моменты или только то, что мы непосредственно используем.\n",
    "\n",
    "Итак, объект — это некая сущность ~~в виде гномика~~, которая обладает какими-то свойствами/атрибутами, если мы говорим о классе объекта и какими-то методами (для понимания это некие функции). Этот самый объект может принимать какие-то данные, как та же функция, например, и производить с этими данными какие-то вычисления, менять как-то свое состояние (значение своих параметров), взаимодействовать с другими объектами или функциями при этом в одной программе может быть много объектов разных классов и они могут каким-то образом друг с другом взаимодействовать описывая какие-то сложные процессы и понятия. Например дольше мы будем объеденять несколько объектов класса перцептрон в объекте класса слой, а объекты класса слой будут определенным образом взаимодействовать между собой, а все это вместе будет объектом класса нейронная сеть со своими методами и свойствами.\n",
    "\n",
    "Наверное, звучит довольно запутанно, но на самом деле, когда разобрался в концепции ООП, то потом все подряд начинаешь писать в этом стиле. Зачем это нужно? Дело в том, что при написании достаточно сложных программ и при решении сложных задач довольно быстро сталкиваешься с тем, что код разрастается, и поддерживать и прослеживать логику становится все сложнее. В коде могут быть сотни и тысячи разных функций и еще больше переменных и параметров. Это все бесконечно усложняет.\n",
    "\n",
    "Поэтому переход к объектно-ориентированной концепции программирования в значительной мере упрощает понимание кода и позволяет описывать более сложные сущности и оперировать более сложными абстракциями, что в свою очередь помогает создавать более сложные в плане продвинутости программы.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашей первоначальной программе были некоторые переменные, которые по смыслу можно отнести к некоторой общей группе или классу. Не путать с понятием класса, которым мы оперируем при классификации наших данных. Имеется в виду, что, например, переменные `weights`, `bias`, `z`, `a` (output) между собой связаны, и их можно представить как некие свойства некоторого объекта. То есть наш объект `perceptron` будет сам в себе хранить веса и смещение, например.\n",
    "\n",
    "Так же и с функциями. Например, функция `forward`, которая принимает некоторые данные и вычисляет `z` и `a`, или функция `predict`, которая принимает нашу выборку и передает по отдельности каждый элемент выборки в `forward`, или функцию активации тоже можно отнести к нашему объекту `perceptron`. То есть эти переменные и эти функции как бы связаны между собой и объединены по смыслу с нашим объектом `perceptron`.\n",
    "\n",
    "Поэтому мы создаем общий класс с названием `Perceptron` и \"помещаем\" в него наши переменные, которые мы называем атрибутами, и функции, которые мы называем методами. Когда мы создаем сам объект `perceptron` на основе этого класса, этот объект хранит в себе свои значения переменных и может быть в разные моменты вызван для произведения нужных нам вычислений. При этом этих объектов может быть и несколько, что нам обязательно нужно будет, когда мы столкнемся с тем, что наш один объект класса перцептрон не способен решить некоторые задачи, а вот уже три этих объекта объединенные в сеть, эти задачи решают."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Описание атрибутов и методов класса Perceptron\n",
    "\n",
    "`__init__`\n",
    "Инициализирует перцептрон с заданными весами и смещением.\n",
    "weights - начальные веса.\n",
    "bias - начальное значение смещения (по умолчанию None).\n",
    "heaviside(self, z):\n",
    "\n",
    "`heaviside`\n",
    "Функция активации (функция Хевисайда).\n",
    "Возвращает 1, если z >= 0.5, иначе 0.\n",
    "\n",
    "`forward`\n",
    "Функция подает/\"прогоняет\" данные в/через перцептрон, вычисляет взвешенную сумму и применяет функцию активации.\n",
    "Возвращает результат применения функции активации.\n",
    "\n",
    "`predict`\n",
    "Функция предсказывает выходные значения всего набору данных.\n",
    "Возвращает список результатов активации для каждого набора входных значений.\n",
    "\n",
    "`__str__`\n",
    "Возвращает строковое представление объекта перцептрона с текущими значениями атрибутов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Магические методы (дополнитеьное пояснение) \n",
    "\n",
    "У объекта могут быть втроенные или как их еще называют магические методы. В Python они выделяются двумя подчеркиваниями в начале и в конце имени. Например `__new__`, `__init__`, `__call__`, `__srt__` и другие. Эти методы позволяют получать разное поведение объекта в разных условиях/ситуациях. Что это значит? Когда мы создаем объект и пишем строке `perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)` то вызывается метод `__init__` нашего класса Perceptron и ему могут быть переданы два параметра: `weights` и `bias`. Причем `weights` обязательно должен быть указан а `bias` если не укажем то примет значение по-умолчанию `None` (на самом деле перед `__init__` будет вызван магический метод `__new__` но мы его пока не используем). То есть это поведение объекта при создании. Если мы например определили метод `__str__`, то при попытке напечатать наш объект: `print(perceptron)` - вызовется метод `__str__` и мы получим строку которую этот метод возвращает. Методы написанные нами вызываются у объекта путем указания их имени через точку. Например в результате выполнения строки `predictions = perceptron.predict(X)` в переменную `prediction` будет записан результат который вернет метод `predict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n"
     ]
    }
   ],
   "source": [
    "# Создаем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "# Выводм текстовое представление объекта\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Данные \"прогона\" последнего объекта\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -1.25], bias: 1.75, z: 0.0, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron.predict(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\nДанные \"прогона\" последнего объекта')\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте сделаем еще одну мелочь, а именно добавим в наш класс магический метод `__call__`. Особой необходимости в этом нет, но как говорят: для закрепления пройденого материала. После добавления этого магического метода мы сможем подвать данные в наш объект и получать предсказание просто написав такой код: `predictions = perceprton(X)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, inputs):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = inputs\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Данные \"прогона\" последнего объекта\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -1.25], bias: 1.75, z: 0.0, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\nДанные \"прогона\" последнего объекта')\n",
    "print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь мы оперируем таким понятием как перцептрон и можем также оперировать таким понятием как обучение перцептрона. То есть мы будем в цикле из первоначального кода вызывать наш перцептрон подавая в него данные и получая его предсказания. На основе этих предсказаний мы будем обучать его. Но перед этим добавим еще один метод в наш класс. А именно метод который будет обучать/изменять веса и смещение нашего объекта. Ведь логично что функция которая изменяет параметры самого объекта должна принадлежать этому же объекту. Это конечно не обязательно но вполне логично зачем нам оставлять ее как некую отдельную функцию если эта функция все-равно всегда работает только с этим объектом. Итак перенесем функцию `update` в наш класс и станет методом для обновления весов и смещения.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (устанавливаются позже в методе forward)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "    # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, h, x):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += h * error * x[i]\n",
    "        self.bias += h * error\n",
    "    \n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [1, 0], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "Процесс обучения из 5 эпох\n",
      "Эпоха обучения 1/5, weights: [-0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/5, weights: [-0.5, 0.75], bias: 1.75\n",
      "Эпоха обучения 3/5, weights: [-0.5, 1.75], bias: 1.75\n",
      "Эпоха обучения 4/5, weights: [-1.5, 1.75], bias: 0.75\n",
      "Эпоха обучения 5/5, weights: [-1.5, 1.75], bias: 0.75\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[1, 0], [1, 1]] предсказанные значения: [0, 1], ожидаемые/истинные значения: [0, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [1, 0], weights: [-1.5, 1.75], bias: 0.75, z: -0.75, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [-1.5, 1.75], bias: 0.75, z: 1.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[1, 0], [1, 1]]  # выборка объектов (два объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1]  # объект x = [1, 0] класса 0, объект x = [1, 1] класса 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "# Обучение (процесс подбора/изменения весов и смещения для нахождения решения задачи)\n",
    "for epoch in range(epochs):\n",
    "    for x, y_true in zip(X, y):    \n",
    "        # Прогон каждого отдельного одного объекта из выборки через перцептрон\n",
    "        prediction = perceptron.forward(x)\n",
    "        \n",
    "        # Вычисление ошибки\n",
    "        error = y_true - prediction\n",
    "        \n",
    "        # Обновление/изменение веса и смещения на основе ошибки\n",
    "        perceptron.update(error, h, x)\n",
    "    \n",
    "    # Отладочная информация\n",
    "    rounded_weights = [round(weight, 2) for weight in perceptron.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "    rounded_bias = round(perceptron.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "    print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Возможно пока еще не очень понятно зачем все эти абстракции в виде классов, объектов. Кода меньше не стало, процесс обучения в целом не отличается. Какие преимущества? Просто мы пока не усложняли нашу задачу, поэтому и преимущества перехода к ООП пока могут быть не столь очевидны. Но давайте сделаем еще один довольно важный шаг и перенесем весь алгоритм обучения также в наш класс. Ведь обучение тоже напрямую относится к нашему перцептрону. Именно поэтому я и назвал главу \"Почти Перцептрон\". После реализации процесса обучения в самом классе можно сказать что у нас уже полноценный Перцептрон. Это разделение на почти перцептрон и полноценный перцептрон довольно условное. В целом нет какого-то правила что считать полноценным, а что неполноценным перцептроном. Да и в целом многие понятия довольно абстракты и условны. Я сделал такое разделение просто для постепенного продвижения от простого к более сложному. И в дальнейшем, например, мы вообще уберем метод обучения из класса нейрона на основе которого будем строить нейронную сеть, потому что метод обучения будет принадлежать такому классу как нейронная сеть а не каждому объекту нейрона в этой сети. Да и в целом мы несколько уйдем от такого понятия как нейрон. Такой класс нам не нужен будет в том виде в котором мы его реализуем сейчас. Потому что все вычисления будут происходить на уровне таких понятий как \"слой нейронной сети\". Но обо всем по-порядку. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Перцептрон"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Перенесем в наш класс метод для обучения перцептрона и решим уже наконец вполне конкретную задачу которая называется \"Логическое И (AND)\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Перцептрона\n",
    "class Perceptron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = self.heaviside    # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "        # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, learning_rate):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += learning_rate * error * self.inputs[i]\n",
    "        self.bias += learning_rate * error\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = y_true - prediction\n",
    "                \n",
    "                # Обновление/изменение веса и смещения на основе ошибки\n",
    "                self.update(error, learning_rate)\n",
    "            \n",
    "            # Отладочная информация\n",
    "            rounded_weights = [round(weight, 2) for weight in self.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "            rounded_bias = round(self.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "            print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Логическое И (AND)\n",
    "\n",
    "Что такое \"Логическое И\"? Возможно объяснение, что это такое тут не требуется, так как с этого начинается практический любой нормальный курс по программированию, но все же еще раз вспомним что это такое и дадим пояснения в контексте нейронных сетей.\n",
    "Задача \"Логическое И\" (AND) заключается в создании логической функции, которая возвращает 1 (истина), только если оба входных значения равны 1. В остальных случаях функция возвращает 0 (ложь).\n",
    "\n",
    "Таблица истинности для операции логического И:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        0        |\n",
    "|   1    |   0    |        0        |\n",
    "|   1    |   1    |        1        |\n",
    "\n",
    "В контексте нейронных сетей можно сказать, что, другими словами, мы имеем четыре объекта в нашей выборке. У каждого объекта по два признака (Вход A и Вход B). И каждый объект отнесен к одному из двух классов (Выход). Задача состоит в том чтобы обучить наш перцептрон так, чтобы подавая в него каждый из объектов (каждый набор признаков объекта) наш перцептрон его бы относил к правильному классу. Возможно ли научить этому перцептрон?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 0, 0, 1]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [1.5, -0.25], bias: 0.75\n",
      "Эпоха обучения 3/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 4/10, weights: [2.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 5/10, weights: [2.5, 0.75], bias: -1.25\n",
      "Эпоха обучения 6/10, weights: [2.5, 1.75], bias: -1.25\n",
      "Эпоха обучения 7/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 8/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 9/10, weights: [2.5, 0.75], bias: -2.25\n",
      "Эпоха обучения 10/10, weights: [2.5, 0.75], bias: -2.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [0, 0, 0, 1], ожидаемые/истинные значения: [0, 0, 0, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [2.5, 0.75], bias: -2.25, z: -2.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [0, 1], weights: [2.5, 0.75], bias: -2.25, z: -1.5, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 0], weights: [2.5, 0.75], bias: -2.25, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [2.5, 0.75], bias: -2.25, z: 1.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 0, 0, 1]  # объекты c признаками [0, 0], [0, 1] и [1, 0] принадлежат классу 0, объект с признаком [1, 1] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=1)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что наш перцептрон научисля решать задачу \"Логическое И\". Касательно кода можно заметить, что мы перенесли метод обучения перцептрона непосредственно в класс Perceptron, перименовали переменную `h` в `learning_rate` и так как у нас каждый набор признаков записывается в методе `forward` в переменную `self.inputs` то мы можем в метод `update` не передавать текущий `x` а просто брать эти значения из `self.inputs`. Можно было так же сделать и с learning_rate, но в будущем мы все равно перенесем этот параметр в другой объект класса Optimaizer, поэтому пока оставим так как есть."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Логическое ИЛИ (OR)\n",
    "\n",
    "Перед тем как сделать следующий шаг давайте рассмотрим еще парочку задач. Первая из них это \"Логичексое ИЛИ (OR)\". Тут принцип абсолютно такой же как и в прошлой задаче за исключением того что \"Логическое ИЛИ\" возвращает истину (1), если хотя бы один из входов истинен. Если оба входа ложны (0), то результатом будет ложь (0).\n",
    "\n",
    "Таблица истинности для операции логического ИЛИ:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        1        |\n",
    "|   1    |   0    |        1        |\n",
    "|   1    |   1    |        1        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 1, 1, 1]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [0.5, -0.25], bias: 1.75\n",
      "Эпоха обучения 3/10, weights: [0.5, -0.25], bias: 0.75\n",
      "Эпоха обучения 4/10, weights: [0.5, 0.75], bias: 0.75\n",
      "Эпоха обучения 5/10, weights: [1.5, 0.75], bias: 0.75\n",
      "Эпоха обучения 6/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 7/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 8/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 9/10, weights: [1.5, 0.75], bias: -0.25\n",
      "Эпоха обучения 10/10, weights: [1.5, 0.75], bias: -0.25\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [0, 1, 1, 1], ожидаемые/истинные значения: [0, 1, 1, 1]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [1.5, 0.75], bias: -0.25, z: -0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [0, 1], weights: [1.5, 0.75], bias: -0.25, z: 0.5, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [1, 0], weights: [1.5, 0.75], bias: -0.25, z: 1.25, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [1, 1], weights: [1.5, 0.75], bias: -0.25, z: 2.0, activation: heaviside, a (output): 1\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1, 1, 1]  # объект c признаком [0, 0] принадлежат классу 0, объекты с признаками [0, 1], [1, 0] и [1, 1] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=1)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как видим, наш перцептрон вполне способен решить задачу логического ИЛИ. И тут мы подходим к интересному моменту. А именно, вернемся к началу. Как можно узнать из различных источников, перцептрон был изобретён в 1957 году Фрэнком Розенблаттом. Это была одна из первых моделей искусственного интеллекта. Вот краткая хронология событий, связанных с перцептроном:\n",
    "\n",
    "**Изобретение и начальные успехи (1957):**\n",
    "- Фрэнк Розенблатт разработал перцептрон, который являлся первой моделью нейрона, способной к обучению.\n",
    "- В 1958 году на перцептроне была проведена демонстрация на IBM 704, вызвавшая значительный интерес в научных кругах и прессе.\n",
    "- В начале 1960-х годов Розенблатт получил финансирование от ВМС США для разработки аппаратной реализации перцептрона, называемой Mark I Perceptron.\n",
    "\n",
    "**Критика и ограничения (1969):**\n",
    "- В 1969 году Марвин Минский и Сеймур Пейперт опубликовали книгу \"Perceptrons\", в которой описали ограничения перцептрона, такие как невозможность решения задачи XOR и других нелинейно разделимых задач.\n",
    "- Их работа показала, что перцептрон не может обрабатывать нелинейные зависимости, что привело к значительному снижению интереса к исследованиям в области нейронных сетей на несколько лет.\n",
    "\n",
    "История также отмечает, что Фрэнк Розенблатт умер в 1971 году в возрасте 43 лет. Хотя его смерть не была основной причиной остановки развития нейронных сетей, она совпала с рядом других факторов, приведших к периоду, известному как \"AI зима\". Это был период снижения интереса и финансирования в области искусственного интеллекта, вызванный завышенными ожиданиями, техническими ограничениями и критическими публикациями. Кстати, стоит отметить, что Розенблатт не утверждал, что перцептрон может решить любые задачи, но сеть из нескольких перцептронов вполне способна решить задачу XOR. Однако, как говорится, ~~AI~~ зима близко.\n",
    "\n",
    "Если нарисовать на графике четыре точки `[[0, 0], [0, 1], [1, 0], [1, 1]]` задачи логического И и просто посмотреть на этот график, то можно легко понять, как эти точки разделить одной прямой линией так, чтобы по одну сторону линии оказались точки одного класса, а по другую — точки другого класса. То же самое можно сделать и для задачи логического ИЛИ. Однако для задачи исключающего ИЛИ (XOR) такую разделительную линию уже невозможно провести. Один перцептрон не способен решить такую задачу, то есть не может правильно классифицировать все точки. Давайте проверим это."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Исключающее ИЛИ (XOR) и однослойный перцептрон\n",
    "\n",
    "XOR (Exclusive OR) - это логическая операция, которая выдает значение истина (1) тогда и только тогда, когда один из входов равен истине (1), а другой равен лжи (0). В отличие от логических операций AND и OR, задача XOR не является линейно разделимой, что делает ее интересной и сложной для ранних нейронных сетей, таких как однослойные перцептроны.\n",
    "\n",
    "Таблица истинности для операции исключающего ИЛИ:\n",
    "| Вход A | Вход B | Выход (A AND B) |\n",
    "|--------|--------|-----------------|\n",
    "|   0    |   0    |        0        |\n",
    "|   0    |   1    |        1        |\n",
    "|   1    |   0    |        1        |\n",
    "|   1    |   1    |        0        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron, inputs: None, weights: [-0.5, -1.25], bias: 1.75, z: None, activation: heaviside, a (output): None\n",
      "\n",
      "Тест до обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 1, 1, 0], ожидаемые/истинные значения: [0, 1, 1, 0]\n",
      "\n",
      "Процесс обучения из 10 эпох\n",
      "Эпоха обучения 1/10, weights: [-0.5, -1.0], bias: 1.75\n",
      "Эпоха обучения 2/10, weights: [-0.5, -1.0], bias: 1.5\n",
      "Эпоха обучения 3/10, weights: [-0.5, -0.75], bias: 1.5\n",
      "Эпоха обучения 4/10, weights: [-0.5, -0.75], bias: 1.25\n",
      "Эпоха обучения 5/10, weights: [-0.5, -0.5], bias: 1.25\n",
      "Эпоха обучения 6/10, weights: [-0.5, -0.5], bias: 1.0\n",
      "Эпоха обучения 7/10, weights: [-0.5, -0.25], bias: 1.0\n",
      "Эпоха обучения 8/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "Эпоха обучения 9/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "Эпоха обучения 10/10, weights: [-0.5, -0.5], bias: 0.75\n",
      "\n",
      "Тест после обучения\n",
      "Для входных данных [[0, 0], [0, 1], [1, 0], [1, 1]] предсказанные значения: [1, 0, 0, 0], ожидаемые/истинные значения: [0, 1, 1, 0]\n",
      "\n",
      "\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон\n",
      "Perceptron, inputs: [0, 0], weights: [-0.5, -0.5], bias: 0.75, z: 0.75, activation: heaviside, a (output): 1\n",
      "Perceptron, inputs: [0, 1], weights: [-0.5, -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 0], weights: [-0.5, -0.5], bias: 0.75, z: 0.25, activation: heaviside, a (output): 0\n",
      "Perceptron, inputs: [1, 1], weights: [-0.5, -0.5], bias: 0.75, z: -0.25, activation: heaviside, a (output): 0\n"
     ]
    }
   ],
   "source": [
    "# Входные данные и целевая метка (ожидаемый результат)\n",
    "X = [[0, 0], [0, 1], [1, 0], [1, 1]]  # выборка объектов (четыре объекта в выборке каждый с двумя признаками)\n",
    "y = [0, 1, 1, 0]  # объекты c признаками [0, 0] и [1, 1] принадлежат классу 0, объекты с признаками [0, 1] и [1, 0] к классу 1\n",
    "\n",
    "# Объявляем и инициализируем объект класса Perceptron\n",
    "perceptron = Perceptron(weights=[-0.5, -1.25], bias=1.75)\n",
    "print(perceptron)\n",
    "\n",
    "# Предсказания до обучения\n",
    "print('\\nТест до обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "# Обучаем перцептрон\n",
    "perceptron.fit(X, y, epochs=10, learning_rate=0.25)\n",
    "\n",
    "# Предсказание на обучающем примере\n",
    "print('\\nТест после обучения')\n",
    "predictions = perceptron(X)\n",
    "print(f'Для входных данных {X} предсказанные значения: {predictions}, ожидаемые/истинные значения: {y}')\n",
    "\n",
    "print('\\n\"Прогоняем\" по-очереди каждый объект выборки через наш обученный перцептрон')\n",
    "for x in X:\n",
    "    perceptron.forward(x)\n",
    "    print(perceptron)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько бы мы не подбирали/обучали веса мы не решим эту задачу одним перцептроном. Но эта задача вполне себе решается многослойным перцептроном. \n",
    "\n",
    "Следующим шагом было бы логично реализовать некий класс для слоя и класс этой самой многослойной сети из перцептронов и убедится, что задача XOR да и многие другие линейно неразделимые объекты можно правльно классифицировать с помощью MLP (многослойного перцептрона), но это просто потеря времени на мой взгляд. Так как перцептрон хоть и можно считать прародителем нейрона, но по сути это всего лишь частный случай \"обычного\" нейрона просто с пороговой/ступенчатой функцией активации, ну или линейной активацией как говорит Википедия. Давайте просто перейдем к понятию нейрон и на нем уже построим нейронную сеть, а потом в качестве примера решим задачу XOR в том числе и на перцептроне. И сможем кстати сразу увидеть разницу и преимущества нейрона над перцептроном.\n",
    "\n",
    "Итак в целом нейрон это тоже самое что и перцептрон. И работает и обучается точно так же. И сеть на нейронах выглядит так же. Хотя, повторюсь, понятие нейрон тоже довольно условное. Как я уже говорил в keras вообще нет такого понятия как нейрон. Там все вычисления происходят в слоях которые представлены в виде матриц и отдельно понятие нейрон никак не выделяется. Но пака мы все равно напишем класс Neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Класс для Нейрона\n",
    "class Neuron:\n",
    "    # Встроенный метод для инициализации объекта\n",
    "    def __init__(self, weights, bias=None, activation=None):\n",
    "        self.inputs = None                  # входные значения (набор признкаков одного объекта x из выборки X)\n",
    "        self.weights = weights              # веса\n",
    "        self.bias = bias                    # смещение\n",
    "        self.z = None                       # взвешенная сумма входов + смещение (вычисляется позже в методе forward)\n",
    "        self.activation = activation        # функция активации\n",
    "        self.a = None                       # результат применения активационной функции (вычисляется позже в методе forward)\n",
    "    \n",
    "    # Метод для активации (пороговая функция активации)\n",
    "    def heaviside(self, z):\n",
    "        return 1 if z >= 0.5 else 0\n",
    "\n",
    "    # Метод для подачи/\"прогона\" данных в/через перцептрон, вычисления z и активации (выхода/ответа)\n",
    "    def forward(self, x):\n",
    "        # Сохраняем поданные в перцептрон входные данные в переменной-атрибуте объекта\n",
    "        self.inputs = x\n",
    "        # Рассчитываем взвешенную сумму (z)\n",
    "        self.z = sum(xi * wi for xi, wi in zip(self.inputs, self.weights)) + (self.bias if self.bias is not None else 0)\n",
    "        # Применяем функцию активации к z\n",
    "        self.a = self.activation(self.z)\n",
    "        return self.a  # возвращаем результат активации (выход/ответ перцептрона output)\n",
    "    \n",
    "        # Метод для обновления/изменения весов и смещения на основе ошибки\n",
    "    def update(self, error, learning_rate):\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += learning_rate * error * self.inputs[i]\n",
    "        self.bias += learning_rate * error\n",
    "\n",
    "    # Метод для обучения\n",
    "    def fit(self, X, y, epochs, learning_rate):\n",
    "        print(f'\\nПроцесс обучения из {epochs} эпох')\n",
    "        for epoch in range(epochs):\n",
    "            for x, y_true in zip(X, y):    \n",
    "                # Прогон каждого отдельного одного объекта из выборки и получение результата\n",
    "                prediction = self.forward(x)\n",
    "                \n",
    "                # Вычисление ошибки\n",
    "                error = y_true - prediction\n",
    "                \n",
    "                # Обновление/изменение веса и смещения на основе ошибки\n",
    "                self.update(error, learning_rate)\n",
    "            \n",
    "            # Отладочная информация\n",
    "            rounded_weights = [round(weight, 2) for weight in self.weights]  # округляем веса до двух знаков после запятой для удобочитаемости\n",
    "            rounded_bias = round(self.bias, 2)  # округляем смещение до двух знаков после запятой для удобочитаемости\n",
    "            print(f'Эпоха обучения {epoch + 1}/{epochs}, weights: {rounded_weights}, bias: {rounded_bias}')\n",
    "\n",
    "    # Встроенный метод для вызова объекта как функции\n",
    "    def __call__(self, X):\n",
    "        return [self.forward(x) for x in X]\n",
    "\n",
    "    # Метод для получения предсказаний по всей выборке\n",
    "    def predict(self, X):\n",
    "        return self.__call__(X)\n",
    "    \n",
    "    # Встроенный метод для строкового представления объекта\n",
    "    def __str__(self):\n",
    "        # self.forward(self.inputs) if self.inputs is not None else ...  # рассчитываем актуальные значения z и a\n",
    "        return f'Perceptron, inputs: {self.inputs}, weights: {self.weights}, bias: {self.bias}, z: {self.z}, ' \\\n",
    "               f'activation: {self.activation.__name__}, a (output): {self.a}'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
